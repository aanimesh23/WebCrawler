<!DOCTYPE html 
    PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
  <title>SLI | Classes-CS178-Notes / Matlab-Classes </title>
  <meta http-equiv='Content-Style-Type' content='text/css' />
  <link rel='stylesheet' href='http://sli.ics.uci.edu/pmwiki/pub/skins/custom/pmwiki.css' type='text/css' />
  <!--HTMLHeader--><style type='text/css'><!--
  ul, ol, pre, dl, p { margin-top:0px; margin-bottom:0px; }
  code.escaped { white-space: nowrap; }
  .vspace { margin-top:1.33em; }
  .indent { margin-left:40px; }
  .outdent { margin-left:40px; text-indent:-40px; }
  a.createlinktext { text-decoration:none; border-bottom:1px dotted gray; }
  a.createlink { text-decoration:none; position:relative; top:-0.5em;
    font-weight:bold; font-size:smaller; border-bottom:none; }
  img { border:0px; }
  .editconflict { color:green; 
  font-style:italic; margin-top:1.33em; margin-bottom:1.33em; }

  table.markup { border:2px dotted #ccf; width:90%; }
  td.markup1, td.markup2 { padding-left:10px; padding-right:10px; }
  table.vert td.markup1 { border-bottom:1px solid #ccf; }
  table.horiz td.markup1 { width:23em; border-right:1px solid #ccf; }
  table.markup caption { text-align:left; }
  div.faq p, div.faq pre { margin-left:2em; }
  div.faq p.question { margin:1em 0 0.75em 0; font-weight:bold; }
  div.faqtoc div.faq * { display:none; }
  div.faqtoc div.faq p.question 
    { display:block; font-weight:normal; margin:0.5em 0 0.5em 20px; line-height:normal; }
  div.faqtoc div.faq p.question * { display:inline; }
   
    .frame 
      { border:1px solid #cccccc; padding:4px; background-color:#f9f9f9; }
    .lfloat { float:left; margin-right:0.5em; }
    .rfloat { float:right; margin-left:0.5em; }
a.varlink { text-decoration:none;}

--></style>  <meta name='robots' content='index,follow' />

</head>
<body>
<!--PageHeaderFmt-->
  <div id='wikilogo'><a href='http://sli.ics.uci.edu'><img src='/pmwiki/pub/skins/custom/SLI_white.png'
    alt='SLI' border='0' /></a></div>
  <div id='wikihead'>
  <form action='http://sli.ics.uci.edu'>
    <!-- <span class='headnav'><a href='http://sli.ics.uci.edu/Classes-CS178-Notes/RecentChanges'
      accesskey='c'>Recent Changes</a> -</span> --> 
    <input type='hidden' name='n' value='Classes-CS178-Notes.Matlab-Classes' />
    <input type='hidden' name='action' value='search' />
    <!-- <a href='http://sli.ics.uci.edu/Site/Search'>Search</a>: -->
    <input type='text' name='q' value='' class='inputbox searchbox' />
    <input type='submit' class='inputbutton searchbutton'
      value='Search' />
    <a href='http://sli.ics.uci.edu/Site/Search'>(?)</a>
  </form></div>
<!--/PageHeaderFmt-->
  <table id='wikimid' width='100%' cellspacing='0' cellpadding='0'><tr>
<!--PageLeftFmt-->
      <td id='wikileft' valign='top'>
        <ul><li><a class='wikilink' href='http://sli.ics.uci.edu/Classes/Classes'>Classes</a>
</li><li><a class='wikilink' href='http://sli.ics.uci.edu/Group/Group'>Group</a>
</li><li><a class='wikilink' href='http://sli.ics.uci.edu/Projects/Projects'>Research</a>
</li><li><a class='urllink' href='http://www.ics.uci.edu/~ihler/pubs.html' rel='nofollow'>Publications</a>
</li><li><a class='wikilink' href='http://sli.ics.uci.edu/Code/Code'>Code</a>
</li></ul><div class='vspace'></div><hr />
<div class='vspace'></div>
</td>
<!--/PageLeftFmt-->
      <td id='wikibody' valign='top'>
<!--PageActionFmt-->
        <div id='wikicmds'><ul><li class='browse'><a class='wikilink' href='http://sli.ics.uci.edu/Classes-CS178-Notes/Matlab-Classes?action=login'>login</a>
</li></ul>
</div>
<!--PageTitleFmt-->
        <div id='wikititle'>
          <div class='pagegroup'><a href='http://sli.ics.uci.edu/Classes-CS178-Notes'>Classes-CS178-Notes</a> /</div>
          <h1 class='pagetitle'>Matlab-Classes</h1></div>
<!--PageText-->
<div id='wikitext'>
<h2>Matlab Object-Oriented Programming and Classes</h2>
<p>Matlab object-oriented programming is a bit awkward and unlike most other
OO languages, but still has some of the elements that make OO programming
useful.  Here I will describe some aspects of Matlab objects, using a class
to construct a k-nearest neighbor classifier as a working example.
</p>
<div class='vspace'></div><h3>Getting started</h3>
<p>First, download the course code into a directory, say,
<code>~ihler/Code/cs178/</code>.
You should see a number of files and directories created there;
for the purposes of this handout, the relevant directory to have is the
<code>@knnClassify</code> directory, which contains the files for the
classifier.
</p>
<p class='vspace'>You should make sure you are either in the directory you downloaded the
files to, or add it to your Matlab path.  For example, use
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre> &gt;&gt; addpath ~ihler/Code/cs178
</pre></div>
<p>to add that directory to Matlab's path.  Note that you should <em>not</em>
be <em>in</em> the <code>@knnClassify</code> directory, nor should you add
it to the path -- only its parent directory.
</p>
<p class='vspace'>We will use "old style" Matlab objects, which consist of a directory
(@-something), which uses one file per member function (private functions
go in a further subdirectory called <code>private</code>).  While there are
some drawbacks to this type of object (and Matlab has since updated
their object representations to be more flexible and give them
more capabilities), this is the type
that is also compatible with Octave, which is useful also.
</p>
<div class='vspace'></div><h3>Using the class</h3>
<p>To create an object of the class type, you can simply call the constructor.
To find out its usage, use <code>help</code>:
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre> &gt;&gt; help knnClassify
  knnClassify(X,Y,...) : create k-nearest-neighbors classifier
  takes no arguments, or training data to be used in constructing the classifier
  alpha: weighted average coefficient (Gaussian weighting); alpha=0 =&gt; simple average
</pre></div>
<p>and we can then use it:
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre> &gt;&gt; Xtr = rand(5,3),     <span  style='color: green;'> % Create feature matrix of 5 data points with 3 features each </span>
 Xtr =                   <span  style='color: green;'> %  (just in case you want to use the same numbers I do...) </span>
    0.4898    0.2760    0.4984 
    0.4456    0.6797    0.9597 
    0.6463    0.6551    0.3404
    0.7094    0.1626    0.5853
    0.7547    0.1190    0.2238
 &gt;&gt; Ytr = [0 0 0 1 1]';  <span  style='color: green;'> % and a corresponding Ytrain of target classes </span>
 &gt;&gt; knn = knnClassify(Xtr,Ytr,3),   <span  style='color: green;'> % Create 3-nearest-nbr classifier with those data</span>
 KNN Classifier, 2 classes, K=3
</pre></div>
<p class='vspace'>Now, to find out what methods are available for a given class,
we can use the <code>methods</code> command to list them:
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre> &gt;&gt; methods knnClassify
 Methods for class knnClassify:

 auc          err          predict      setClasses   
 confusion    getClasses   predictSoft  setK         
 display      knnClassify  roc          train        
</pre></div>
<p>Our most typical operations will be <code>train</code> and <code>predict</code>, which
train a model on training data, and predict the current model on new data, respectively.
Typically, when constructor functions accept training data, they simply call the
<code>train</code> function.
To see what parameters <code>train</code> takes, we need to differentiate <em>which</em>
train we mean:
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre> &gt;&gt; help knnClassify/train
   knn=train(knn,Xtrain,Ytrain) : Batch training for knn; just memorize data
</pre></div>
<p class='vspace'>Using this calling pattern, we can re-train the model with e.g.,
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre> &gt;&gt; knn = train(knn, Xtr,Ytr);
</pre></div>
<p>and predict with
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre> &gt;&gt; Xte = rand(2,3),               <span  style='color: green;'> % Make two test data points (same # of features!)</span>
 Xte =
    0.7513    0.5060    0.8909
    0.2551    0.6991    0.9593
 &gt;&gt; Yte = [0 1]';                  <span  style='color: green;'> %   and some test target values for goot measure</span>
 &gt;&gt; Yhat= predict(knn,Xte),        <span  style='color: green;'> % Make prediction for those points:</span>
 Yhat =
     0
     0
</pre></div>
<p>Two points are worth noting: First, member functions are typically called by
passing the object as the first argument of the function.  They can also be
called in a more typical format, <code>knn.train(Xtr,Ytr)</code>, but both are
implemented in exactly the same way.
</p>
<p class='vspace'>Second, functions that modify the class in some way (such as <code>train</code>)
should actually return (and set) the object variable.  Matlab cannot generally
update variables by reference (recent object changes relax this point), and
so the object must be returned in order to modify it.
</p>
<p class='vspace'>We can also use accessor functions to get or set object properties, such as:
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre> &gt;&gt; knn = setK(knn, 1),            <span  style='color: green;'> % Change to a 1-nearest nbr classifier</span>
 KNN Classifier, 2 classes, K=1
</pre></div>
<p>Again, we actually return the modified object variable, and set <code>kdd</code>
to be equal to the returned value.
</p>
<div class='vspace'></div><h3>The object constructor</h3>
<p>Let's take a closer look at how the constructor function
<code>knnClassify.m</code> works.  First, here is the file header:
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre> function obj = knnClassify(Xtr,Ytr,K)
 <span  style='color: green;'> % knnClassify([X,Y,K]) : create k-nearest-neighbors classifier</span>
 <span  style='color: green;'> % takes no arguments, or training data to be used in constructing the classifier</span>
</pre></div>
<p>The first line declares the function itself, and any returned variables.
The first set of comments in the file are output for the help
command (<code>help knnClassify</code>), and should contain basic usage information.
</p>
<p class='vspace'>Default values are a bit awkward; typically, you can check how many variables
were passed in and fill in any missing ones (positional defaults):
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre>   if (nargin &lt; 3) K = 1; end;
</pre></div>
<p>Another typical approach is to require that the caller pass an empty matrix,
which can be tested for and filled in with a default value.
</p>
<p class='vspace'>The basic form of an object is simply a Matlab structure with a bit of extra
gloss on top; we declare the member variables as if it were a structure, and
then call a function to define it as a class:
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre>   obj.K=K; obj.Xtrain=[]; obj.Ytrain=[]; obj.classes=[];
   obj=class(obj,'knnClassify');
</pre></div>
<p>I usually do this immediately with empty values, since the variable fields
must always be declared in the same order.  Note also that return values are
specified by name, so if <code>obj</code> is listed as the return variable, whatever
variable is called <code>obj</code> when the function ends is returned.
</p>
<p class='vspace'>I typically also allow <code>train</code> to be called automatically by just passing
the data into the constructor:
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre>   if (nargin &gt; 0)
     obj = train(obj,Xtr,Ytr);
     obj = setK(obj,K);
   end;
</pre></div>
<p>Or, these can be called manually after.
</p>
<p class='vspace'>As an aside, Matlab objects can be converted into structures, allowing their
internal data to be accessed by anyone:
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre> &gt;&gt; s = struct(knn),
 s = 
          K: 1
     Xtrain: [5x3 double]
     Ytrain: [5x1 double]
    classes: [2x1 double]
</pre></div>
<p>This can be useful if you're trying to access something in an object while debugging,
but is usually non-reversible, i.e., it is difficult to modify <code>s</code> and transform it
back to an object afterwards.
</p>
<div class='vspace'></div><h3>The <code>train</code> function</h3>
<p>Training for a k-nearest neighbor classifier is trivial; we simply memorize the data:
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre> function obj=train(obj, Xtr,Ytr)
 <span  style='color: green;'> % knn=train(knn,Xtrain,Ytrain) : Batch training for knn; just memorize data</span>
   obj.Xtrain = Xtr;
   obj.Ytrain = Ytr;
   obj.classes= unique(Ytr);
</pre></div>
<p>One minor point -- I always keep a column vector <code>obj.classes</code> in each classifier.
The internal implementation of the classifier predicts a positive integer <img class='TrueLatexImage' style='vertical-align:middle;' border=0 src="http://sli.ics.uci.edu/pmwiki/pub/latexcache/3fa649761d69091d3b08de5566039e5e.png" />,
and then returns <code>obj.classes(c)</code>.  This way, the class values can be
non-consecutive, non-standard, and even of different Matlab types (characters or whatever)
without any difficulty.  Some classifiers are implemented specifically for binary
classification problems, in which case we can simply check that the number of classes is only
two.
</p>
<div class='vspace'></div><h3>The <code>predict</code> function</h3>
<p>In order to predict with a k-nearest neighbor classifier, we simply search the stored
training data for the nearest points, in terms of their sum of squared differences.
The file header,
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre> function Yte = predict(obj,Xte)
 <span  style='color: green;'> % Yhat = predict(knn, Xtest) : make a nearest-neighbor prediction on test data  </span>

   [Ntr,Mtr] = size(obj.Xtrain);          <span  style='color: green;'> % get size of training, test data</span>
   [Nte,Mte] = size(Xte);
   K = min(obj.K, Ntr);                   <span  style='color: green;'> % can't have more than Ntrain neighbors</span>
   Yte = repmat(obj.Ytrain(1), [Nte,1]);  <span  style='color: green;'> % make Ytest the same data type as Ytrain</span>
</pre></div>
<p>gets the number of training and test data, and their dimensions ($M$, which should be the
same for both), and makes sure $K$ is valid.  We pre-initialize <code>Yte</code> by
copying (<code>repmat</code> = repeat matrix) one of the training data to the correct size;
pre-allocating the correct vector size helps Matlab avoid constantly re-allocating
memory for <code>Yte</code>,
and using <code>repmat</code> ensures it has the right variable type.
</p>
<p class='vspace'>Next, for each test data point, we compute the distance from all training data,
for example:
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre>   for i=1:Nte,                <span  style='color: green;'> % For each test example:</span>
     dist=zeros(Ntr,1);        <span  style='color: green;'> % pre-allocate a distance vector</span>
     for j=1:Ntr,              <span  style='color: green;'> % and compute distance from all Ntr training data</span>
       dist(j)=sum( (obj.Xtrain(j,:)-Xte(i,:)).^2 ); 
     end;
   end;
</pre></div>
<p>However, this turns out to be awfully slow; Matlab is interpreted, and often has
trouble performing for-loops quickly.  For better performance, you may
learn to ``vectorize'' your calculations, performing them all in one step:
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre>   dist = sum( (obj.Xtrain - repmat(Xte(i,:),[Ntr,1]) ).^2 , 2);
</pre></div>
<p>This copies the <code>Xte</code> data point to be the same size as <code>Xtrain</code>,
then subtracts the two matrices, squares the entries (element-wise), and sums
them over their 2nd dimension (the features), leaving a column-vector of distances
exactly like the for-loop above.  Even harder to read but slightly faster still
is to use the <code>bsxfun</code> function, which performs operators on differently-sized
matrices (so that you don't need to use <code>repmat</code> to copy the data point):
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre>   dist = sum( bsxfun( @minus, obj.Xtrain, Xte(i,:) ).^2 , 2);
</pre></div>
<p>All this is useful if you are finding Matlab very slow, but takes a while to get used to.
</p>
<p class='vspace'>Finally, we find the $K$ nearest data examples, and find the majority vote among them:
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre>   [dst,idx] = sort(dist);       <span  style='color: green;'> % find nearest neighbors over Xtrain</span>
   idx=idx(1:K);                 <span  style='color: green;'> % keep nearest K data points</span>
   nClasses=length(obj.classes);
   count = zeros(1,nClasses);    <span  style='color: green;'> % count up how many in each class</span>
   for c=1:nClasses, count(c)=sum( obj.Ytrain(idx)==obj.classes(c) ); end;
   [nil cMax] = max(count);      <span  style='color: green;'> % find the (position of the) largest #</span>
   Yte(i) = obj.classes(cMax);   <span  style='color: green;'> % and save the prediction</span>
</pre></div>
<p>A useful trick here -- both <code>sort</code> and <code>max</code> can return both the
sorted / maximum value (first return value) <em>and</em> the position of those values
(as the second return value).  So <code>idx</code> is a list of the training data points
in order from nearest to farthest, and <code>cMax</code> is the index of the class with
the largest <code>count</code> value.
</p>
<p class='vspace'>Also, <code>obj.Ytrain(idx)==obj.classes(c)</code> is a binary vector, with "1"
when the equality condition is satisified and "0" if not.  Then, <code>sum</code>
counts up the number of "1" entries.
</p>
<div class='vspace'></div><h3>Measuring errors</h3>
<p>A few functions are common to almost all predictors; for example,
frequently, we want to evalute the error rate, measuring how often our model makes
incorrect predictions on a data set (e.g., the training or validation error).
Functions like <code>err</code> do this easily:
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre> &gt;&gt; J = err(knn, Xte, Yte),       <span  style='color: green;'> % evalute the empirical error rate on these data</span>
 J = 
     0.5000
</pre></div>
<p>To get more information, we may want to look at the confusion matrix:
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre> &gt;&gt; C = confusion(knn, Xte, Yte), <span  style='color: green;'> % evalute the confusion matrix:</span>
 C =                             
      1     0                    <span  style='color: green;'> % one true class zero (column), predicted 0 (row)</span>
      1     0                    <span  style='color: green;'> % one true class zero (column), predicted 1 (row)</span>
</pre></div>
<p>Similar functions (<code>mse</code>, etc.) are found in regression classes.
</p>
<p class='vspace'>Many classifiers also support <em>soft</em> predictions, which express some level
of confidence in the possible outcomes.  For example, in kNN, we might return
the fraction of the $K$ neighbors in each class (rather than just the decision);
<code>predictSoft</code> returns a length-<code>nClasses</code> vector of such confidences
for each data point:
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre> &gt;&gt; knn = setK(knn, 3);           <span  style='color: green;'> % poinless for k=1...</span>
 &gt;&gt; ySoft = predictSoft(knn,Xte), <span  style='color: green;'> % make soft predictions:</span>
 ySoft =
     0.6667    0.3333            <span  style='color: green;'> % test point 1 has 66% confidence in class 0</span>
     1.0000         0            <span  style='color: green;'> % test point 2 has 100% confidence in class 0</span>
</pre></div>
<p>These soft scores are useful in computing, for example, ROC curves
(note that this only works for binary classifications):
</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >
<pre>  [fpr,tpr,tnr] = roc(knn,Xte,Yte);  <span  style='color: green;'> % find info for ROC curve:</span>
  plot(fpr,tpr,'-');            <span  style='color: green;'> % (not very interesting for these data, though...)</span>
</pre></div>
<p>and the area under the curve can be computed with <code>auc.m</code>.
</p>
<div class='vspace'></div>
</div>

      </td>
    </tr></table>
<!--PageFooterFmt-->
  <div id='wikifoot'>
    <div class='footnav' style='float:left'> Last modified January 05, 2015, at 12:06 PM</div>
    <div class='footnav' style='float:right; text-align:right'>
    <a href="http://www.ics.uci.edu">Bren School of Information and Computer Science</a><br>
    <a href="http://www.uci.edu">University of California, Irvine</a>
    </div>
  </div>
<!--HTMLFooter--><script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(["_setAccount", "UA-24148957-2"]);
	_gaq.push(["_trackPageview"]);
	(function() {
	  var ga = document.createElement("script"); ga.type = "text/javascript"; ga.async = true;
	  ga.src = ("https:" == document.location.protocol ? "https://ssl" : "http://www") + ".google-analytics.com/ga.js";
	  var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(ga, s);
	  })();
</script>
</body>
</html>
