<!DOCTYPE html>
<html>
<title>CS 274A | Winter 2017</title>
<meta name="viewport" content="width=device-width, initial-scale=1">


<!--MATERIAL BELOW TO BE INCLUDED ON ALL SITE PAGES--> 
<link rel="stylesheet" href="http://www.ics.uci.edu/~smyth/test/localw3.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css"> <!--mini icons--> 
<link rel="stylesheet" href="http://www.w3schools.com/lib/w3-theme-blue.css">  <!-- color theme -->
<link rel="stylesheet" type="text/css" href="localstyle.css">  <!-- my own style -->
<link rel="stylesheet" type="text/css" href="http://www.ics.uci.edu/~smyth/courses/class_style.css">  <!-- Padhraic's class style --->  
<link rel="icon" type="image/png" href="https://news.uci.edu/wp-content/uploads/2014/12/favicon.png"/> <!-- favicon -->

<body class="w3-animate-opacity">
  
<div style="margin-left:10%;  margin-right:10%;  margin-top:30px">  
 
 

<!-- -------------------------------------------------------------------------------------------- -->
 
<h4> <span style="font-weight: bold;"> CS 274A: Probabilistic Learning: Theory and Algorithms, Winter 2017 </span></h4> 

<h6> General Information </h6> 
<ul>
<li><b> Time: </b> Monday and Wednesday, 5:00 to 6:20pm </li>
<li><b> Location: </b> MSTB 120 </li>
<li><b> Instructor: </b>  
<a href="http://www.ics.uci.edu/~smyth">Professor Padhraic Smyth</a></li> 
<li><b> Reader: </b> <a href="http://www.ics.uci.edu/~enalisni/">Eric Nalisnick</a></li>
<li><b>  
<a href="syllabus.html">Syllabus</a></b>  </li>
<li> <b> <a href="notes.html">Notes</a></b>: Links to notes, texts, and background
reading </li>
<li><b> Office Hours:</b> 9:30 to 10:30 on Mondays, and 10 to 11 on Tuesdays, DBH 4216
<li><b> Questions? </b> please use the 
<a href="https://piazza.com/uci/winter2017/cs274a/home">Piazza class Website</a> for class-related questions and discussion. If
you have a question post it to Piazza rather than sending an email to the instructor.</li>
</ul>
</p>

<p>
<h6>Homeworks</h6>
<ul>
<li> <b> Homework 1 </b>   | <a href="homeworks/hw1.pdf">PDF</a> | <a href="homeworks/hw1.tex">LaTeX</a>|
Hardcopy due in class on Wednesday January 18th 
</li>
<li> <b> Homework 2 </b>   | <a href="homeworks/hw2.pdf">PDF</a> | <a href="homeworks/hw2.tex">LaTeX</a>|
Hardcopy due to Eric's office by 5pm on Friday January 27th (can be dropped off between 3pm and 5pm that day).
</li> 
<li> <b> Homework 3 </b>   | <a href="homeworks/hw3.pdf">PDF</a> | <a href="homeworks/hw3.tex">LaTeX</a>|
Hardcopy due to Eric's office by 5pm on Friday February 3rd (can be dropped off between 3pm and 5pm that day).
</li> 
<li> <b> Homework 4 </b>  | <a href="homeworks/hw4.pdf">PDF</a> | <a href="homeworks/hw4_prompt.tex">LaTeX</a>|
Hardcopy due in class, Code to be uploaded to EEE dropbox by start of class, on Wednesday Feb 22nd
</li> 
<li> <b> Homework 5 </b>  
</li>
<li> <b> Homework 6 </b>  
</li>
</ul>
</p>
 

<p>
<h6> Prerequisites for taking this class </h6>
Knowledge of basic concepts in probability, multivariate calculus, and linear algebra are required for this course. 
Please note that a good understanding of probability in particular is important for this class.  
</p>  

<p>
<h6> Course Goals </h6>
Students will develop a comprehensive understanding of probabilistic approaches to learning from data. 
Probabilistic learning is a key component in many areas within modern computer science, 
including artificial intelligence, data mining, speech recognition, computer vision, bioinformatics, and so forth. 
The course will provide a tutorial introduction to the basic principles of probabilistic modeling and then 
demonstrate the application of these principles to the analysis, development, and practical 
use of machine learning algorithms.  Topics covered will include probabilistic modeling, 
defining likelihoods, parameter estimation using likelihood and Bayesian techniques, 
probabilistic approaches to classification, clustering, and regression, and related topics 
such as model selection and bias/variance tradeoffs.
</p>

<p>
<h6> Grading Policy </h6>
Final grades will be based on a combination of homework assignments and exams: 30% homeworks, 30% midterm, and 40% final. 
No credit for late homeworks - instead your lowest scoring homework will be dropped and not included in your score.  
</p>

<p>
<h6> Academic Integrity </h6>
Students are expected to be read and be familiar with the <a href="http://www.ics.uci.edu/~smyth/courses/academic_integrity">Academic
Integrity Policy</a> for this class. 
Failure to adhere to this policy can result in a student receiving a failing grade in the class.  
</p>

<!--- <p>
<h6> UCI Catalogue Description </h6>
Probabilistic Learning: Theory and Algorithms: A unified probabilistic framework for learning algorithms. 
Classical pattern recognition algorithms, probabilistic mixture models, kernel methods, 
hidden Markov models, among others. Multivariate data analysis concepts for classification and clustering. 
Methodologies such as cross-validation and bootstrap. Prerequisites: basic calculus and linear algebra.  
</p>
--->
  

</body>