
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Computational Vision | ICS | UC Irvine</title>
  <link rel="stylesheet" type="text/css" href="/stylesheets/screen.css" media="all">
</head>

<body id="publications">
  <div id="outerframe">
  <div id="header">
    <h1>Computational Vision at UC Irvine &nbsp;<img src="/images/eye_small.jpg" alt="small eye"></h1>
  </div>
  <div id="tabs">
    <ul id="tabnav">
      <li id="home_tab"><a href="/index.html">home</a></li>
      <li id="projects_tab"><a href="/projects.html">projects</a></li>
      <li id="people_tab"><a href="/people.html">people</a></li>
      <li id="publications_tab"><a href="/publications.html">publications</a></li>
      <li id="datasets_tab"><a href="/datasets/index.html">datasets</a></li>
      <li id="events_tab"><a href="/events.html">events</a></li>
      <li id="courses_tab"><a href="/courses.html">courses</a></li>
      <li id="contact_tab"><a href="/contact.html">contact</a></li>
      <li id="links_tab"><a href="/links.html">links</a></li>
    </ul>
  </div>

  <div id="content">
    <div id="paper_title">First-Person Pose Recognition using Egocentric Workspaces</div>
    <div id="paper_authors"><a href="/people/7.html">Grégory&nbsp;Rogez</a>, <a href="/people/10.html">James&nbsp;Supančič</a>, <a href="/people/20.html">Deva&nbsp;Ramanan</a></div>
    <div id="abstract">
      <img style="float:left;" src="icon_drop.jpg" alt="icon">
      We tackle the problem of estimating the 3D pose of an individual’s
upper limbs (arms+hands) from a chest mounted
depth-camera. Importantly, we consider pose estimation
during everyday interactions with objects. Past work shows
that strong pose+viewpoint priors and depth-based features
are crucial for robust performance. In egocentric views,
hands and arms are observable within a well defined volume
in front of the camera. We call this volume an egocentric
workspace. A notable property is that hand appearance
correlates with workspace location. To exploit this correlation,
we classify arm+hand configurations in a global egocentric
coordinate frame, rather than a local scanning window.
This greatly simplify the architecture and improves
performance. We propose an efficient pipeline which 1) generates
synthetic workspace exemplars for training using a
virtual chest-mounted camera whose intrinsic parameters
match our physical camera, 2) computes perspective-aware
depth features on this entire volume and 3) recognizes discrete
arm+hand pose classes through a sparse multi-class
SVM. We achieve state-of-the-art hand pose recognition
performance from egocentric RGB-D images in real-time.

    </div>
    <div id="bibtext">
      <h3>Download: <a href="/papers/RogezSR_CVPR_2015/RogezSR_CVPR_2015.pdf">pdf</a></h3>
      <h3>Text Reference</h3>
Grégory Rogez, James&nbsp;S. Supan\vc i\vc &nbsp;III, and Deva Ramanan.
First-person pose recognition using egocentric workspaces.
In <em>CVPR</em>. 2015.<br>
<h3>BibTeX Reference</h3>
@inproceedings{RogezSR_CVPR_2015,<br>
&nbsp;&nbsp;&nbsp;&nbsp;AUTHOR = "Rogez, Gr{\'e}gory and Supan{\vc}i{\vc} III, James S. and Ramanan, Deva",<br>
&nbsp;&nbsp;&nbsp;&nbsp;TITLE = "First-Person Pose Recognition using Egocentric Workspaces",<br>
&nbsp;&nbsp;&nbsp;&nbsp;BOOKTITLE = "CVPR",<br>
&nbsp;&nbsp;&nbsp;&nbsp;YEAR = "2015",<br>
&nbsp;&nbsp;&nbsp;&nbsp;tag = "people"<br>
}<br>
    </div>
  </div>
  <div id="footer">
    <div>
      <a href="/">Computational Vision</a> |
      <a href="http://www.ics.uci.edu/">School of Information and Computer Sciences</a> |
      <a href="http://www.uci.edu/">UC Irvine</a>
    </div>
    <div id="updated">&copy; 2007-2016 UC Irvine</div>
  </div>
  </div>
</body>
</html>

