# -*- coding: utf-8 -*-
"""
Created on Wed Jan  4 11:52:53 2017 
"""

# ---------------------------------------------------------------------------------------
# CS 175, WINTER 2017: ASSIGNMENT 1
# It is strongly recommended that you read the assigned sections of Chapters 1,2,3,5
# in the NLTK book before starting to work on this assignment
#
# General notes
#	- do not change the names of the functions or parameters or variable being returned
#   - add your own code within each function where appropriate
#   - some of the functions are partly specified in the form "variable = ...." as a
#         suggestion for how the code could be written. You can delete these lines
#         and use your own variables and code flow if you wish 
#	- add comments inline in the text to explain what you are doing 
#	- feel free to add error checking if you wish (but we will not grade you on this)
# 	- docstrings are provided below to document the purpose of each function. 
#	- when you are done submit a copy of your edited version of this file, as Assignment1.py
#   - make sure you text your code before you submit it
#
# Grading
#   - problems 1 and 2 are each worth 25 points, problem 3 is worth 50 points
#   - points will be deducted if the code does not work on simple test cases, if
#       the code is not general and only works on special cases, if there are little or
#       no comments.
# 
# ---------------------------------------------------------------------------------------

import nltk, re, pprint
from nltk.book import *
from nltk import word_tokenize
from urllib import request
from bs4 import BeautifulSoup

# Important: first time you are working with NLTK, run nltk.download() and download all 
# of the material needed for the NLTK book - only need to do this once.

# ---------------------------------------------------------------------------------------
# PROBLEM 1
# Complete the definition of the function below so that it can take in a string
# and return the percentage of alphabetical characters in a string that match a particular
# alphabetic character, where matching is not case-sensitive. The percentage is computed
# relative to the number of alphabetic characters in the string (so numbers, punctuation,
# white space, and all other non-alphabetic characters are ignored).
# Notes
#   - you may want to use the function FreqDist to compute the frequency of a letter
# 	- Read Section 3 of Chapter 1 to understand how to use the FreqDist method
# ---------------------------------------------------------------------------------------

def letter_percentage(text,letter):
	"""
	Parameters:
	text: string
	letter: a single alphabetical character (in lower case, e.g., 'a', 'b', ...)
	
	Returns:
	percentage: the percentage of alphabetic characters in <text> that match <letter>
		  where a match is defined irrespective of the case of the characters in <text>
				
	Example:
	letter_percentage('This is a cat.','t')  returns 20.0
	"""
	character_list = .....
	character_frequencies = ....
	letter_frequency =  ....
	percentage = ....
	return percentage


# ---------------------------------------------------------------------------------------
# PROBLEM 2
# Complete the definition of the function below so that it can take in a URL of a Web page
# (as a string) and return the first k word tokens on the page (or up to k word tokens if
# there are fewer than k). If no value for k is specified when the function is called it 
# should return all of the word tokens on the page by default.
# The function should use the NLTK word_tokenize function to find word tokens
# and BeautifulSoup to remove HTML tags. See Chapter 3 in the NLTK text for examples. 
# ---------------------------------------------------------------------------------------
def first_words(url,k=0):
	"""
	Parameters:
	url: string specifying a URL
	k: (optional) integer specifying the number of word tokens to return
	
	Returns:
	The first k word tokens on the page (using the word_tokenize function from NLTK)
	(or if k is not specified, it returns all the word tokens on the page)
				
	Example:
	first_words('http://www.ics.uci.edu/~smyth/courses/cs175', 10)  
	   returns ['CS', '175', '|', 'Winter', '2017', 'CS', '175', ':', 'Project', 'in']
	"""
	html = ......
	rawtext = .......
	tokens = .....
	if k>0:
		return( tokens[:k] )
	else:
		return( tokens )
		

# ---------------------------------------------------------------------------------------
# PROBLEM 3
# Complete the definition of the function below so that it can take as input either
# (a) a string or (b) a list of tokens of type nltk.text.Text
# convert the string to word tokens, run the NLTK part of speech parser on the word tokens
# using the 'universal' tagset, print out to the screen the percentage of tokens in the
# that correspond to each type of tag, and return a list of pairs of tokens and tags.
# Note:
# 	- Read Section 1 of Chapter 5 for information about part of speech tagging
# 	- for word tokenization use the NLTK word_tokenize function 
#  	- Print out the tags in order of decreasing frequency of occurrence
#	- Percentages printed out should be formatted to 2 decimal places of precision
# ---------------------------------------------------------------------------------------
def parts_of_speech(s):
	"""
	Parameters:
	s: input text as a string 
	
	Returns:
	The list of tokens and their POS tags from the string s, as a list of sublists 
	Prints out the total number of tokens and percentage of tokens with each tag 
				
	Example:
	s = 'This is a sentence. And this is a second sentence! Cool.'
	z1, z2 = parts_of_speech(s)  
		Total number of tokens is 14
		Tag: DET           Percentage of tokens =  28.57
		Tag: .     Percentage of tokens =  21.43
		Tag: NOUN          Percentage of tokens =  21.43
		....
	"""
	
	# if the input is a string tokenize the string into word tokens
	# and tag the word tokens...otherwise assume its a tokenized list and proceed
	.......
	tokens = .....
		
	# Compute and print the total number of tokens   
	n = .......
	print('\nTotal number of tokens is',n)
	
	# tag the tokens with the NLTK part of speech tagger (using 'universal' tags)
	tokens_and_tags = .....  # list of each token and its tag, 
							 # e.g., [('This', 'DET'), ('is', 'VERB'),..
	tags = .... # extract just the tags as a list, e.g., ['DET', 'VERB', 'DET', 'NOUN',..
	
	# count how often each of the tags occurs using FreqDist (from NLTK)
	.....
	tag_counts = .....
	sorted_tag_counts = .....
	
	# loop through the tags, order of decreasing frequency, and print percentages
	for ...... 
		......
 
	return( tokens_and_tags , tags )
	
 
		 
	
	
	