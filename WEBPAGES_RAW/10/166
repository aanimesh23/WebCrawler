



<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">
<html>
<head>
<title>UCI Machine Learning Repository: Chess (King-Rook vs. King-Knight) Data Set: Support</title>

<!-- Stylesheet link -->
<link rel="stylesheet" type="text/css" href="../assets/ml.css" />

<script language="JavaScript" type="text/javascript">
<!--
function checkform ( form )
{
  // see http://www.thesitewizard.com/archive/validation.shtml
  // for an explanation of this script and how to use it on your
  // own website

  // ** START **
  if (form.q.value == "")
  {
    alert( "Please enter search terms." );
    form.q.focus();
    return false ;
  }

  if (getCheckedValue(form.sitesearch) == "ics.uci.edu" && form.q.value.indexOf("site:archive.ics.uci.edu/ml") == -1)
  {
    form.q.value = form.q.value + " site:archive.ics.uci.edu/ml";
  }

  // ** END **
  return true ;
}

// return the value of the radio button that is checked
// return an empty string if none are checked, or
// there are no radio buttons
function getCheckedValue(radioObj) {
	if(!radioObj)
		return "";
	var radioLength = radioObj.length;
	if(radioLength == undefined)
		if(radioObj.checked)
			return radioObj.value;
		else
			return "";
	for(var i = 0; i < radioLength; i++) {
		if(radioObj[i].checked) {
			return radioObj[i].value;
		}
	}
	return "";
}
//-->
</script>

</head>

<body>


<!-- SITE HEADER (INCLUDES LOGO AND SEARCH BOX) -->

<table width=100% bgcolor="#003366">
<tr>
	<td>
		<span class="normal"><a href="../index.html" 
alt="Home"><img src="../assets/logo.gif" 
border=0></img></a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://cml.ics.uci.edu"><font color="FFDD33">Center for Machine Learning and Intelligent Systems</font></a></span>
	</td>
	<td width=100% valign=top align="right">
		<span class="whitetext">
		<a href="../about.html">About</a>&nbsp;
		<a href="../citation_policy.html">Citation Policy</a>&nbsp;
		<a href="../donation_policy.html">Donate a Data Set</a>&nbsp;
		<a href="../contact.html">Contact</a>
		</span>

		<br>
		<br>
		<!-- Search Google -->

		<FORM method=GET action=http://www.google.com/custom onsubmit="return checkform(this);">
		<INPUT TYPE=text name=q size=30 maxlength=255 value="">
		<INPUT type=submit name=sa VALUE="Search">
		<INPUT type=hidden name=cof VALUE="AH:center;LH:130;L:http://archive.ics.uci.edu/assets/logo.gif;LW:384;AWFID:869c0b2eaa8d518e;">
		<input type=hidden name=domains value="ics.uci.edu">
		<br>
		<input type=radio name=sitesearch value="ics.uci.edu" checked> <span class="whitetext"><font size="1">Repository</font></span>
		<input type=radio name=sitesearch value=""> <span class="whitetext"><font size="1">Web</font></span>
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
		<A HREF=http://www.google.com/search><IMG SRC=http://www.google.com/logos/Logo_25blk.gif border=0 ALT=Google align=middle height=27></A>
		<br>
		</FORM>
		<!-- Search Google -->


		<span class="whitetext"><a href="../datasets.html"><font size="3" color="#FFDD33"><b>View ALL Data Sets</b></font></a></span>
		<br>
	</td>
</tr>
</table>

<br />
<table width=100% border=0 cellpadding=2><tr><td>


   <table><tr>
     <td valign=top>
	<p>
	<span class="heading"><b>Chess (King-Rook vs. King-Knight) Data Set</b></span>

		
		<img src="../assets/MLimages/Large24.jpg" hspace=20 vspace=10 align=right />		<p class="normal">Below are papers that cite this data set, with context shown.
		Papers were automatically harvested and associated with this data set, in collaboration with <a href="http://rexa.info">Rexa.info</a>.</p>
		<img src="../assets/rexa.jpg" />
		<p class="normal"><a href="/ml/datasets/Chess+(King-Rook+vs.+King-Knight)">Return to Chess (King-Rook vs. King-Knight) data set page</a>.
		<hr><p class="normal"><a name="5b07457d7b968260c0c1a712f9120a243bcfbf8c"></a><i>Manuel Oliveira. <a href="http://rexa.info/paper/5b07457d7b968260c0c1a712f9120a243bcfbf8c">Library Release Form Name of Author: Stanley Robson de Medeiros Oliveira Title of Thesis: Data Transformation For Privacy-Preserving Data Mining Degree: Doctor of Philosophy Year this Degree Granted</a>. University of Alberta Library. 2005. </i><br><br>Pumsb (d o = 74); (b) The error produced on the dataset <b>Chess</b> (d o =37). ......................119 7.4 The error produced on the dataset Pumsb over vertically partitioned data. . . 121 List of Tables 6.1 Thread of selecting the attributes on the party k<br></p><hr><p class="normal"><a name="9b1522e8a25d84453b24d3891ac99e165d3eebaa"></a><i>Ira Cohen and Fabio Gagliardi Cozman and Nicu Sebe and Marcelo Cesar Cirelo and Thomas S. Huang. <a href="http://rexa.info/paper/9b1522e8a25d84453b24d3891ac99e165d3eebaa">Semisupervised Learning of Classifiers: Theory, Algorithms, and Their Application to Human-Computer Interaction</a>. IEEE Trans. Pattern Anal. Mach. Intell, 26. 2004. </i><br><br>EMTAN can sometimes improve performance over TAN with just labeled data (Shuttle). With the <b>Chess</b> dataset, discarding the unlabeled data and using only TAN seems the best approach. We have compared two likelihood based structure learning methods (K2 and MCMC) on the same datasets as well [34], showing<br></p><hr><p class="normal"><a name="7125dc87ceddf952f1840074b40ac0526dcc03dc"></a><i>Marcus Hutter and Marco Zaffalon. <a href="http://rexa.info/paper/7125dc87ceddf952f1840074b40ac0526dcc03dc">Distribution of Mutual Information from Complete and Incomplete Data</a>. CoRR, csLG/0403025. 2004. </i><br><br>600 900 1200 1500 1800 2100 2400 2700 3000 Instance number Prediction accuracy  <b>Chess</b>  FF F Figure 2: Comparison of the prediction accuracies of the naive Bayes with filters F and FF on the Chess data set. The gray area denotes di�erences that are not statistically significant. The remaining cases are described by means of the following figures. Figure 2 shows that FF allowed the naive Bayes to<br></p><hr><p class="normal"><a name="32c4d28ceaa19d2a6906dfa39df99da7026c9cc5"></a><i>Douglas Burdick and Manuel Calimlim and Jason Flannick and Johannes Gehrke and Tomi Yiu. <a href="http://rexa.info/paper/32c4d28ceaa19d2a6906dfa39df99da7026c9cc5">MAFIA: A Performance Study of Mining Maximal Frequent Itemsets</a>. FIMI. 2003. </i><br><br>0.1 0.12 Min Sup (%) Time (s) NONE ADAPTIVE Compression on BMS-WebView-2 10 100 1000 10000 0 0.01 0.02 0.03 0.04 0.05 0.06 Min Sup (%) Time (s) NONE ADAPTIVE Figure 8. Compression on more sparse datasets Compression on <b>Chess</b> 1 10 100 1000 0 5 10 15 20 25 30 35 Min Sup (%) Time (s) NONE ADAPTIVE Compression on Pumsb 10 100 1000 10000 0 10 20 30 40 50 60 70 Min Sup (%) Time (s) NONE ADAPTIVE<br></p><hr><p class="normal"><a name="a0c05cdac8e9929a4113d37aa2588e7ae70a6b76"></a><i>Tanzeem Choudhury and James M. Rehg and Vladimir Pavlovic and Alex Pentland. <a href="http://rexa.info/paper/a0c05cdac8e9929a4113d37aa2588e7ae70a6b76">Boosting and Structure Learning in Dynamic Bayesian Networks for Audio-Visual Speaker Detection</a>. ICPR (3). 2002. </i><br><br>accuracy. We compare its performance to both standard structure learning and boosted parameter learning on a �xed structure. We present results for speaker detection and for the UCI  <b>chess</b>  dataset. 1. Introduction Human-centered user-interfaces based on vision and speech present challenging sensing problems in which multiple sources of information must be combined to infer the user's actions<br></p><hr><p class="normal"><a name="3fa8ab593f1fd58f33109aae497ca1fb67732c35"></a><i>Marco Zaffalon and Marcus Hutter. <a href="http://rexa.info/paper/3fa8ab593f1fd58f33109aae497ca1fb67732c35">Robust Feature Selection by Mutual Information Distributions</a>. CoRR, csAI/0206006. 2002. </i><br><br>The remaining cases are described by means of the following figures. Figure 2 shows that FF allowed the naive Bayes to significantly do better predictions than F for the greatest part of the <b>Chess</b> data set. The maximum di�erence in prediction accuracy is obtained at instance 422, where the accuracies are 0.889 and 0.832 for the cases FF and F, respectively. Figure 2 does not report the BF case,<br></p><hr><p class="normal"><a name="d25c86892bfa80849ecd629de4c45936a52a1590"></a><i>Michael G. Madden. <a href="http://rexa.info/paper/d25c86892bfa80849ecd629de4c45936a52a1590">Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm</a>. CoRR, csLG/0211003. 2002. </i><br><br>were selected that had these characteristics and that were not very small. The datasets are listed in Table 1. Dataset #I #A <b>Chess</b> (King & Rook vs King & Pawn) 3196 32 Wisconsin Breast Cancer Diagnosis 699 9 LED-24 (17 irrelevant attributes) 3200 24 DNA: Splice Junction Gene Sequences<br></p><hr><p class="normal"><a name="7bea464dce753e6523458d22de98a96004c1aac8"></a><i>James Bailey and Thomas Manoukian and Kotagiri Ramamohanarao. <a href="http://rexa.info/paper/7bea464dce753e6523458d22de98a96004c1aac8">Fast Algorithms for Mining Emerging Patterns</a>. PKDD. 2002. </i><br><br>(Vehicle, Waveform and Letter-recognition) though. Analysis of the vehicle and <b>chess</b> datasets aid in explaining this outcome (supporting figures have been excluded due to lack of space). It is clear that classification accuracy is dependent upon finding patterns that strongly discriminate<br></p><hr><p class="normal"><a name="5bc77452a8b6552aed91aa3294068d7110dc54af"></a><i>Russell Greiner and Wei Zhou. <a href="http://rexa.info/paper/5bc77452a8b6552aed91aa3294068d7110dc54af">Structural Extension to Logistic Regression: Discriminative Parameter Learning of Belief Net Classifiers</a>. AAAI/IAAI. 2002. </i><br><br>discretization [FI93]. Our accuracy values were based on 5-fold cross validation for small data, and holdout method for large data [Koh95]. See [GZ02],[FGG97] for more information about these datasets. We use the <b>CHESS</b> dataset (36 binary or ternary attributes) to illustrate the basic behaviour of the algorithms. Figure 2(a) shows the performance, on this dataset, of our NB+ELR ("Na�iveBayes<br></p><hr><p class="normal"><a name="5976a7013ed27ef8dc3309ee0427e9e110b5323d"></a><i>Boonserm Kijsirikul and Sukree Sinthupinyo and Kongsak Chongkasemwongse. <a href="http://rexa.info/paper/5976a7013ed27ef8dc3309ee0427e9e110b5323d">Approximate Match of Rules Using Backpropagation Neural Networks</a>. Machine Learning, 44. 2001. </i><br><br>& Feng, 1990) for learning rules. Normally we used rules produced byPROGOL as the input to BANNAR. However in our experiments on the finite element mesh design and the King-Rook-King <b>chess</b> endgame datasets described below, PROGOL failed to produce a rule set within a reasonable time. In those experiments, we employed GOLEM developed by the same research group of PROGOL. We then compared the results<br></p><hr><p class="normal"><a name="ca1c2b19089d0ca0d4069b04c35d6f6c4312db79"></a><i>Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao and Limsoon Wong. <a href="http://rexa.info/paper/ca1c2b19089d0ca0d4069b04c35d6f6c4312db79">DeEPs: A New Instance-based Discovery and Classification System</a>. Proceedings of the Fourth European Conference on Principles and Practice of Knowledge Discovery in Databases. 2001. </i><br><br>(This will be explained in Section 8.3). Note that for data sets such as <b>chess</b>  flare, splice, mushroom, voting, soybean-l, t-t-t, and zoo which do not contain any continuous attributes, DeEPs does not require an ff. The accuracies of k-nearest neighbor and C5.0<br></p><hr><p class="normal"><a name="beeb203c082359f4e141e1767a14f09449a5a717"></a><i>Jie Cheng and Russell Greiner. <a href="http://rexa.info/paper/beeb203c082359f4e141e1767a14f09449a5a717">Learning Bayesian Belief Network Classifiers: Algorithms and System</a>. Canadian Conference on AI. 2001. </i><br><br>Wrapper(multi-net) with ordering = W-MN-O, Wrapper(multi-net) with feature selection = W-MN-FS and Wrapper(multi-net) with feature selection with ordering = WMN-FS-O. The ordering for the <b>Chess</b> data set is the reversed order of the features that appear in the data set since it is more reasonable, the ordering we use for other data sets are simply the order of the features that appear in the data<br></p><hr><p class="normal"><a name="111c890abe7dc9f26523d1c59b7a75a04b69256b"></a><i>Jinyan Li and Guozhu Dong and Kotagiri Ramamohanarao. <a href="http://rexa.info/paper/111c890abe7dc9f26523d1c59b7a75a04b69256b">Instance-Based Classification by Emerging Patterns</a>. PKDD. 2000. </i><br><br>(as explained in [10]). Note that for the datasets such as <b>chess</b>  flare, nursery, splice, mushroom, voting, soybean-l, t-t-t, and zoo which do not contain any continuous attributes, DeEPs does not need ff. Columns 5, 6, 7, 8, and 9 give the<br></p><hr><p class="normal"><a name="cd11168bb19fd462bc59beefbe670bc4eb31e3eb"></a><i>Mark A. Hall. <a href="http://rexa.info/paper/cd11168bb19fd462bc59beefbe670bc4eb31e3eb">Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning</a>. Doctor of Philosophy at The University of Waikato. 1999. </i><br><br>without feature selection using merged subsets. . . . . . . . . . . . . . . . . . . . . . . . . . 115 6.9 Top eight feature-class correlations assigned by CFS-UC and CFS-MDL on the <b>chess</b> end-game dataset. . . . . . . . . . . . . . . . . . . . . . . . 116 7.1 Comparison between naive Bayes without feature selection and naive Bayes with feature selection by the wrapper and CFS. . . . . . . . . . . .<br></p><hr><p class="normal"><a name="ac8fe867e1d16d4d09f9bd759ba46699055c7ca6"></a><i>Yk Huhtala and Juha K�rkk�inen and Pasi Porkka and Hannu Toivonen. <a href="http://rexa.info/paper/ac8fe867e1d16d4d09f9bd759ba46699055c7ca6">Efficient Discovery of Functional and Approximate Dependencies Using Partitions</a>. ICDE. 1998. </i><br><br>out of memory. Table 2 shows performance results for TANE/MEM in the approximate dependency discovery task, for different thresholds ''. Results for the Hepatitis, Wisconsin breast cancer, and <b>Chess</b> data sets are also presented graphically in Figure 3: N '' =N 0 stands for the number of approximate dependencies found relative to the case for functional dependencies; similarly, Time '' =Time 0 denotes<br></p><hr><p class="normal"><a name="c334718c7e09d2671197a8c9526018de1d816903"></a><i>Adam J. Grove and Dale Schuurmans. <a href="http://rexa.info/paper/c334718c7e09d2671197a8c9526018de1d816903">Boosting in the Limit: Maximizing the Margin of Learned Ensembles</a>. AAAI/IAAI. 1998. </i><br><br>that this depends crucially on the base learner always being able to find a sufficiently good hypothesis if one exists; see Section 5 for further discussion of this issue. 8 However, for some large data sets, <b>chess</b> and splice, we inverted the train/test proportions. FindAttrTest Adaboost LP-Adaboost DualLPboost Data set error% win% error% margin error% win% margin error% win% margin Audiology 52.30<br></p><hr><p class="normal"><a name="bf6cec50b7f7d48d105c8c649210cc3a42d3d71e"></a><i>Ron Kohavi. <a href="http://rexa.info/paper/bf6cec50b7f7d48d105c8c649210cc3a42d3d71e">Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid</a>. KDD. 1996. </i><br><br>which is a Bayes network restricted to a tree topology. The results are promising and running times should scale up, but the approach is still restrictive. For example, their accuracy for the <b>Chess</b> dataset, which contains high-order interactions is about 93%, much lower then C4.5 and NBTree, which achieve accuracies above 99%. Conclusions We have described a new algorithm, NBTree, which is a hybrid<br></p><hr><p class="normal"><a name="00c705fd319a8886a15103ab320040ae719c4283"></a><i>Ron Kohavi and Dan Sommerfield. <a href="http://rexa.info/paper/00c705fd319a8886a15103ab320040ae719c4283">Feature Subset Selection Using the Wrapper Method: Overfitting and Dynamic Search Space Topology</a>. KDD. 1995. </i><br><br>in error. The execution time on a Sparc20 for feature subset selection using ID3 ranged from under five minutes for breast-cancer (Wisconsin), cleve, heart, and vote to about an hour for most datasets. DNA took 29 hours, followed by <b>chess</b> at four hours. The DNA run took so long because of ever increasing estimates that did not really improve the test-set accuracy. 7 Conclusions We reviewed the<br></p><hr><p class="normal"><a name="128dbeaae1b5807933aa2a5983bc1765dcaf6f85"></a><i>Brian R. Gaines. <a href="http://rexa.info/paper/128dbeaae1b5807933aa2a5983bc1765dcaf6f85">Structured and Unstructured Induction with EDAGs</a>. KDD. 1995. </i><br><br>EDAG for this problem with that obtained from human <b>Chess</b> experts. Before this is done, the following section illustrates the induction of EDAGs for a simple chess problem. 2 Modeling a Simple Chess Dataset Quinlan (1979) describes ID3 models of 7 rook versus knight end game situations of increasing difficulty. The third problem involves 647 cases with 4 3-valued attributes, 3 2-valued attributes, and<br></p><hr><p class="normal"><a name="287a92657decc181f6842e52b05c1fa17e5ab277"></a><i>Hankil Yoon and Khaled A. Alsabti and Sanjay Ranka. <a href="http://rexa.info/paper/287a92657decc181f6842e52b05c1fa17e5ab277">Tree-based Incremental Classification for Large Datasets</a>. CISE Department, University of Florida. </i><br><br>very quickly and identify a method that better suits to the application. 5.2 Experimental results with <b>chess</b> dataset The chess dataset obtained from [BKM98] contains 25,000 training records and 3,056 test records. There are 18 class values and each record consists of 6 attributes, all of which are numeric<br></p><hr><p class="normal"><a name="03a71aaf988c71c8022be08734da8e376f7fe037"></a><i>Omid Madani and David M. Pennock and Gary William Flake. <a href="http://rexa.info/paper/03a71aaf988c71c8022be08734da8e376f7fe037">Co-Validation: Using Model Disagreement to Validate Classification Algorithms</a>. Yahoo! Research Labs. </i><br><br>unlabeled data does not tend to wildly underestimate error, even though it's theoretically possible. 3 Experiments We conducted experiments on the 20 Newsgroups and Reuters-21578 test categorization datasets 1 , and the Votes, <b>Chess</b>  Adult, and Optics datasets from the UCI collection [BKM98]. We chose 1 Available from http://www.ics.uci.edu/ and http://www.daviddlewis.com/resources/testcollections/ two<br></p><hr><p class="normal"><a name="d342517262ff52ffd3566bd8f520b36723486aa3"></a><i>M. A. Galway and Michael G. Madden. <a href="http://rexa.info/paper/d342517262ff52ffd3566bd8f520b36723486aa3">DEPARTMENT OF INFORMATION TECHNOLOGY technical report NUIG-IT-011002 Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm</a>. Department of Information Technology National University of Ireland, Galway. </i><br><br>were selected that had these characteristics and that were not very small. The datasets are listed in Table 1. Dataset #I #A <b>Chess</b> (King & Rook vs King & Pawn) 3196 32 Wisconsin Breast Cancer Diagnosis 699 9 LED-24 (17 irrelevant attributes) 3200 24 DNA: Splice Junction Gene Sequences<br></p><hr><p class="normal"><a name="d1f5f29cee39c05c852c7fe7a1857064bc7957da"></a><i>BayesianClassifi552 Pat Langley and Wayne Iba. <a href="http://rexa.info/paper/d1f5f29cee39c05c852c7fe7a1857064bc7957da">In Proceedings of the Tenth National ConferenceonArtifi256 Intelligence( 42840</a>. Lambda Kevin Thompson. </i><br><br>C4 algorithm (Buntine & Caruana, 1991) and an algorithm that simply predicts the modal class. The five domains, from the UCI database collection (Murphy& Aha, 1992), include the ``small'' soybean dataset, <b>chess</b> end games involving aking-12 ok--126-22 wn confrontatwobiologidata set into 80% training instances and 20% testinpairs of training and test sets. The table shows the mean accuracy and 95%<br></p><hr><p class="normal"><a name="12fe4ef85ae4ef89437a10d0a7b0daf32af2be21"></a><i>Jerome H. Friedman and Ron Kohavi and Youngkeol Yun. <a href="http://rexa.info/paper/12fe4ef85ae4ef89437a10d0a7b0daf32af2be21">To appear in AAAI-96 Lazy Decision Trees</a>. Statistics Department and Stanford Linear Accelerator Center Stanford University. </i><br><br>fast algorithm. The largest running time by far was for mushroom with 8.4 Sparc-10 cpu minutes per crossvalidation fold (equivalent to a run), followed by <b>chess</b> with 1.59 cpu minutes. These datasets have 8124 instances and 3196 instances, respectively. From the table we can see that simple ID3 is generally inferior, as is C4.5 without pruning. Pruning improves C4.5-NP's performance, except for<br></p><hr><p class="normal"><a name="7de1dca96d7e6789dadc875a7f1b070f9d65fff5"></a><i>Grigorios Tsoumakas and Ioannis P. Vlahavas. <a href="http://rexa.info/paper/7de1dca96d7e6789dadc875a7f1b070f9d65fff5">Fuzzy Meta-Learning: Preliminary Results</a>. Greek Secretariat for Research and Technology. </i><br><br>from the Machine Learning Repository at the University of Irvine, California (Blake & Merz, 1998). These were the adult and <b>chess</b> data sets, large enough (} 1000 examples) to simulate distributed environment. Only two domains were selected at this stage of our research to investigate the performance of the suggested methodology. The<br></p><hr><p class="normal"><a name="3e9ebff12a232c9f091156827e92c55d259b95f3"></a><i>Nikunj C. Oza and Stuart J. Russell. <a href="http://rexa.info/paper/3e9ebff12a232c9f091156827e92c55d259b95f3">Online Bagging and Boosting</a>. Computer Science Division University of California. </i><br><br>AdaBoost performed significantly worse and online boosting performed marginally worse. On the Car Evaluation and <b>Chess</b> datasets, AdaBoost and online boosting performed significantly better than Naive Bayes. On the Nursery dataset, AdaBoost performed significantly better and online boosting performed marginally better. 5<br></p>


	</td></tr></table>



<hr>

<p class="normal"><a href="/datasets/Chess+(King-Rook+vs.+King-Knight)">Return to Chess (King-Rook vs. King-Knight) data set page</a>.


<table cellpadding=5 align=center><tr valign=center>
		<td><p class="normal">Supported By:</p></td>
        <td><img src="../assets/nsfe.gif" height=60 /> </td>
        <td><p class="normal">&nbsp;In Collaboration With:</p></td>
        <td><img src="../assets/rexaSmall.jpg" /></td>
</tr></table>

<center>
<span class="normal">
<a href="../about.html">About</a>&nbsp;&nbsp;||&nbsp;
<a href="../citation_policy.html">Citation Policy</a>&nbsp;&nbsp;||&nbsp;
<a href="../donation_policy.html">Donation Policy</a>&nbsp;&nbsp;||&nbsp;
<a href="../contact.html">Contact</a>&nbsp;&nbsp;||&nbsp;
<a href="http://cml.ics.uci.edu">CML</a>
</span>
</center>




</body>
</html>
