<html>
<head>
<link rel="stylesheet" type="text/css" href="../ihler.css">
</head>

<body>
<div id="navleft">
<CENTER>
   <H2>Code Packages</H2>
</CENTER>
<HR noShade>
<p style="text-indent:-1em; margin-left:1em">
<a href="kde.html">KDE Toolbox</a>
<p style="text-indent:-1em; margin-left:1em">
<a href="event.html">Event Detection</a>
<p style="text-indent:-1em; margin-left:1em">
<a href="adaptive.html">Adaptive Inference</a>
<p style="text-indent:-1em; margin-left:1em">
<a href="http://sli.ics.uci.edu/Code/GPRTimeshift/">Gaussian Process Regression with Time-shifts</a>
</p>
<hr noShade>
</div>
<div class="content">

<head>
<LINK rel="stylesheet" type="text/css" href="../ihler.css">
</head>

<font face="Arial, Helvetica, sans-serif" size=5 color="#000000"> 
Kernel Density Estimation Toolbox for MATLAB (R13) </font><br><br>
<h1>MATLAB KDE Class Description</h1>
<p>The KDE class is a general matlab class for k-dimensional kernel density estimation. 
  It is written in a mix of matlab ".m" files and MEX/C++ code. Thus, to use it 
  you will need to be able to compile C++ code for Matlab. Note that the default 
  compiler for Windows does <b>not</b> support C++, so you will need GCC under 
  Linux, or GCC or Visual C++ for Windows. <a href=http://www.bloodshed.net>Bloodshed</a> 
  supplies a nice development environment along with the <a href="http://www.mingw.org">MinGW</a> 
  compiler. See <a target="_top" href="http://gnumex.sourceforge.net/">this page</a> for help setting up
  MEX with MinGW.</p>
<p>[NOTE: Since several compiled mexglx and dll files are included, you may not need to re-compile the toolbox at all; however, I recommend it if possible for compatibility reasons.]</p>
<p>Kernels supported are: </p>
<ul>
  <li><p>Gaussian</p></li>
  <li><p>Epanetchnikov (truncated quadratic)</p></li>
  <li><p>Laplacian (Double-exponential)</p></li>
</ul>
<p>For multivariate density estimates, the code supports product kernels -- kernels 
  which are products of the kernel function in each dimension. For example, for 
  Gaussian kernels this is equivalent to requiring a diagonal covariance. It can 
  also support non-uniform kernel bandwidths -- i.e. bandwidths which vary over 
  kernel centers. </p>
<p>The implementation uses "kd-trees", a heirarchical representation for point 
  sets which caches sufficient statistics about point locations etc. in order 
  to achieve potential speedups in computation. For the Epanetchnikov kernel this 
  can translate into speedups with no loss of precision; but for kernels with 
  infinite support it provides an approximation tolerance level, which allows 
  tradeoffs between evaluation quality and computation speed. In particular, we 
  implement Alex Gray's "Dual Tree" evaluation algorithm; see <it><i>Gray and 
  Moore, "Very Fast Multivariate Kernel Density Estimation using via Computational 
  Geometry", in Proceedings, Joint Stat. Meeting 2003</i></it> for more details. 
  This gives a tolerance parameter which is a percent error (from the exact, N^2 
  computation) on the value at any evaluated point. In general, "tolerance" parameters 
  in the matlab code / notes refers to this percent tolerance. This percentage 
  error translates to an absolute additive error on the mean log-likelihood, for 
  example. An exception to this is the gradient calcuation functions, which calculate 
  using an absolute tolerance value. This is due to the difficulty of finding 
  a percentage bound when the function calculated is not strictly positive. </p>
<p> We have also recently implemented the so-called Improved Fast Gauss Transform,
  described in [Yang, Duraiswami, and Gumerov, "Improved Fast Gauss Transform",
  submitted to the Siam Journal of Scientific Computing].  This often performs
  MUCH faster than the dual tree algorithm mentioned above, but the error bounds
  which control the computation are often quite loose, and somewhat unwieldy
  (for example, it is difficult to obtain the fractional error bounds provided & 
  used by the dual tree methods and other functions in the KDE toolbox).  Thus 
  for the moment we have left the IFGT separate, with alternate controls for 
  computational complexity (see below, and the file "evalIFGT.m").  </p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>


<h1>Getting Started </h1>

<p> <a href="kde.tar.gz">Download</a> and unzip the KDE class to a directory called <tt>@kde</tt>. </p>

<p> (If desired) Compile the MEX functions. This can be done by going to the
  "@kde/mex" directory in Matlab, and <b>copying and pasting</b> the code from 
  the "<tt>makemex.m</tt>" file into the Matlab window.  If this fails, make 
  sure that MEX / C++ compilation works. The KDE toolbox is tested in Matlab R13 
  and later; it may work in ealier versions as well. 
  Re-compiling may not be required, depending on your platform and version;
  "mexglx" (Linux 32-bit), "mexa64" (Linux 64-bit), and "dll" (Windows 32-bit)
  files are included.  If you have trouble, recompile.</p>

<p> Thanks to Ankur Datta for compiling <a href="kde.mac.zip">Mac versions of the MEX files</a> and making them
available.  (I do not even own a Mac and cannot vouch for their operation, etc.; use at your own risk.)

<p> NOTE: MS Visual C++ has a bug in dealing with "static const" variables; I
      think there is a patch available, or you can change these to #defines.</p>

<p>  Operate from the class' parent directory, or add it to your MATLAB path
    (e.g. if you unzip to "myhome/@kde", cd in matlab to the "myhome" dir,
     or add it to the path.) </p>

<p> Objects of type KDE may be created by e.g. </p>
<blockquote> 
  <p><tt>p = kde( rand(2,1000), [.05;.03] );</tt> % Gaussian kernel, 2D % BW = 
    .05 in dim 1, .03 in dim 2. </p>
  <p><tt>p = kde( rand(2,1000), .05, ones(1,1000) );</tt> % Same as above, but 
    uniform BW and % specifying weights </p>
  <p><tt>p = kde( rand(2,1000), .05, ones(1,1000), 'Epanetchnikov');</tt> % Quadratic 
    kernel; just 'E' or 'e' also works </p>
  <p><tt>p = kde( rand(2,1000), 'rot' );</tt> % Gaussian kernel, 2D, BW chosen 
    by "rule of thumb" (below) </p>
</blockquote>
<p> To see the kernel shape types, you can use: </p>
<blockquote> 
  <p><tt>plot(-3:.01:3, evaluate(kde(0,1,1,T),-3:.01:3) );</tt> % where T = 'G', 
    'E', or 'L' </p>
</blockquote>
<p> Kernel sizes may be selected automatically using e.g. </p>
<blockquote> 
  <p><tt>p = ksize(p, 'lcv');</tt> % 1D Likelihood-based search for BW </p>
  <p><tt>p = ksize(p, 'rot');</tt> % "Rule of Thumb"; Silverman '86 / Scott '92 
  </p>
  <p><tt>p = ksize(p, 'hall');</tt> % Plug-in type estimator (estimates each dim. 
    separately) </p>
</blockquote>
<p> Density estimates may be visualized using e.g. </p>
<blockquote> 
  <p><tt>plot(p); </tt> </p>
</blockquote>
<p> or </p>
<blockquote>
  <p><tt>mesh(hist(p));</tt> </p>
</blockquote>
<p> See &quot;<tt>help kde/plot</tt>&quot; and &quot;<tt>help kde/hist</tt>&quot; 
  for more information. </p>
<p> Also, the demonstration programs<tt> @kde/examples/demo_kde_#.m</tt> may be 
  helpful. </p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>



<h1>Usage Examples </h1>
<p>The demonstration programs in <code>@kde/examples/demo_kde_#.m</code> (where <code>#</code> 
is one of <code>1,2,3</code>) may be helpful. </p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>



<h1> KDE Matlab class definition </h1>
<p>The following is a simple list of all accessible functions for the KDE class. 
Use &quot;<tt>help functionname</tt>&quot; in Matlab for more information. </p>
<p></p>
<p><b><font size="+1">Constructors:</font></b> </p>
<table width="90%" border="1" cellspacing="0" cellpadding="2">
  <tr> 
    <td width="23%"><p>kde( )</td>
    <td width="77%"><p>empty kde </td>
  </tr>
  <tr> 
    <td width="23%"><p>kde( kde )</td>
    <td width="77%"><p>re-construct kde from points, weights, bw, etc.</td>
  </tr>
  <tr> 
    <td width="23%"><code>kde( points, bw )</code></td>
    <td width="77%"><p>construct Gauss kde with weights 1/N</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>kde( points, bw, weights)</code></td>
    <td width="77%"><p> construct Gaussian kde</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>kde( points, bw, weights,type)</code></td>
    <td width="77%"><p>potentially non-Gaussian</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>marginal( kde, dim)</code></td>
    <td width="77%"><p>marginalize to the given dimensions</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>condition( kde, dim, A)</code></td>
    <td width="77%"><p>marginalize to ~dim and weight by K(x_i(dim),a(dim))</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>resample( kde, [kstype] )</code></td>
    <td width="77%"><p>draw N samples from kde & use to construct a new kde</p></td>
  </tr>
  <tr> 
    <td width="23%"><code>reduce( kde, ...)</code></td>
    <td width="77%"><p>construct a "reduced" density estimate (fewer points)</p></td>
  </tr>
  <tr>
    <td width="23%"><code>joinTrees( t1, t2 )</code></td>
    <td width="77%"><p>make a new tree with t1 and t2 as the children of a new root 
      node</p></td>
  </tr>
</table>
<p> </p>
<p></p>
<p><b><font size="+1">Accessors: (data access, extremely limited or no processing 
  req'd)</font></b> </p>
<table width="90%" border="1" cellspacing="0" cellpadding="2">
  <tr> 
    <td height="24" colspan="2"><code>getType(kde)</code></td>
    <td width="79%" height="24"><p>return the kernel type of the KDE ('Gaussian', 
      etc)</p> </td>
  </tr>
  <tr> 
    <td colspan="2">&nbsp;</td>
    <td width="79%">&nbsp;</td>
  </tr>
  <tr> 
    <td colspan="2"><code>getDim</code></td>
    <td width="79%"><p>get the dimension of the data</p> </td>
  </tr>
  <tr> 
    <td colspan="2"><code>getNpts</code></td>
    <td width="79%"><p> get the # of kernel locations</p></td>
  </tr>
  <tr> 
    <td colspan="2"><code>getNeff</code></td>
    <td width="79%"><p>"effective" # of kernels (accounts for non-uniform weights)</p> 
    </td>
  </tr>
  <tr> 
    <td colspan="2">&nbsp;</td>
    <td width="79%">&nbsp;</td>
  </tr>
  <tr> 
    <td colspan="2"><code>getPoints(kde)</code></td>
    <td width="79%"><p>Ndim x Npoints array of kernel locations</p> </td>
  </tr>
  <tr> 
    <td colspan="2"><code>adjustPoints(p,delta)</code></td>
    <td width="79%"><p>shift points of P by delta (by reference!)</p> </td>
  </tr>
  <tr> 
    <td colspan="2"><code>rescale(kde,alpha)</code></td>
    <td width="79%"><p>rescale a KDE by the (vector) alpha</p> </td>
  </tr>
  <tr> 
    <td colspan="2">&nbsp;</td>
    <td width="79%">&nbsp;</td>
  </tr>
  <tr> 
    <td colspan="2"><code>getBW(kde,index)</code></td>
    <td width="79%"><p>return the bandwidth assoc. with x_i (Ndim x length(index))</p></td>
  </tr>
  <tr> 
    <td colspan="2"><code>adjustBW(kde,newBW)</code></td>
    <td width="79%"><p>set the bandwidth(s) of the KDE (by reference!) <i>Note: cannot 
      change from a uniform -> non-uniform bandwidth</i></p> </td>
  </tr>
  <tr> 
    <td colspan="2"><code>ksize</code></td>
    <td width="79%"><p>automatic bandwidth selection via a number of methods</p> </td>
  </tr>
  <tr> 
    <td width="2%">&nbsp;</td>
    <td width="19%"><code>LCV</code></td>
    <td width="79%"><p>1D search using max leave-one-out likelihood criterion</p></td>
  </tr>
  <tr> 
    <td width="2%">&nbsp;</td>
    <td width="19%"><code>HALL, HJSM</code></td>
    <td width="79%"><p>Plug-in estimator with good asymptotics; MISE criterion </p></td>
  </tr>
  <tr> 
    <td width="2%">&nbsp;</td>
    <td width="19%"><code>ROT, MSP</code></td>
    <td width="79%"><p>Fast standard-deviaion based methods; AMISE criterion </p></td>
  </tr>
  <tr> 
    <td width="2%">&nbsp;</td>
    <td width="19%"><code>LOCAL</code></td>
    <td width="79%"><p>Like LCV, but makes BW propto k-th NN distance (k=sqrt(N))</p> 
    </td>
  </tr>
  <tr> 
    <td height="10" colspan="2">&nbsp;</td>
    <td width="79%" height="10">&nbsp;</td>
  </tr>
  <tr> 
    <td colspan="2"><code>getWeights</code></td>
    <td width="79%"><p>[1 x Npts] array of kernel weights </p></td>
  </tr>
  <tr> 
    <td colspan="2"><code>adjustWeights</code></td>
    <td width="79%"><p>set kernel weights (by reference!)</p></td>
  </tr>
  <tr> 
    <td colspan="2">&nbsp;</td>
    <td width="79%">&nbsp;</td>
  </tr>
  <tr> 
    <td colspan="2"><code>sample(P,Np,KSType)</code></td>
    <td width="79%"><p>draw Np new samples from P and set BW according to KSType</p></td>
  </tr>
  <tr> 
    <td colspan="2">&nbsp;</td>
    <td width="79%">&nbsp;</td>
  </tr>
</table>
<p><b><font size="+1">Display: (visualization / description)</font></b> </p>
<table width="90%" border="1" cellspacing="0" cellpadding="2">
  <tr> 
    <td width="23%"><code>plot(kde...)</code></td>
    <td width="77%"><p>plot the specified dimensions of the KDE locations</p></td>
  </tr>
  <tr> 
    <td width="23%"><code>hist(kde...)</code></td>
    <td width="77%"><p>discretize the kde at uniform bin lengths display : text output 
      describing the KDE</p></td>
  </tr>
  <tr> 
    <td width="23%"><code>double</code></td>
    <td width="77%"><p>boolean evaluation of the KDE (non-empty)</p> </td>
  </tr>
</table>
<p></p>
<p><font size="+1"><b>Statistics: (useful stats & operations on a kde)</b></font> 
</p>
<table width="90%" border="1" cellspacing="0" cellpadding="2">
  <tr> 
    <td width="23%"><code>mean</code></td>
    <td width="77%"><p>find the (weighted) mean of the kernel centers</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>covar</code></td>
    <td width="77%"><p>find the (weighted) covariance of the kernel centers</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>knn(kde, points, k)</code></td>
    <td width="77%"><p>find the k nearest neighbors of each of points in kde</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>entropy</code></td>
    <td width="77%"><p>estimate the entropy of the KDE</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>kld</code></td>
    <td width="77%"><p>estimate divergence between two KDEs</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>evaluate(kde, x[,tol])</code></td>
    <td width="77%"><p>evaluate KDE at a set of points x</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>evaluate(p, p2 [,tol])</code></td>
    <td width="77%"><p>same as above, x = p2.pts (if we've already built a tree)</p> 
    </td>
  </tr>
  <tr> 
    <td width="23%"><code>evalIFGT(kde, x, N)</code></td>
    <td width="77%"><p>evaluate using the N-term IFGT (requires uniform BW Gaussian kernels)</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>evalIFGT(p, p2, N)</code></td>
    <td width="77%"><p><same as above, x = p2.pts (if we've already built a tree)</p> </td>
  </tr>
  <tr> 
    <td width="23%"> <code> evalAvgLogL(kde, x)</code> </td>
    <td width="77%"><p>compute Mean( log( evaluate(kde, x) ))</p></td>
  </tr>
  <tr> 
    <td width="23%"><code>evalAvgLogL(kde, kde2)</code></td>
    <td width="77%"><p>same as above, but use the weights of kde2</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>evalAvgLogL(kde)</code></td>
    <td width="77%"><p>self-eval; leave-one-out option</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>llGrad(kde,kde2)</code></td>
    <td width="77%"><p>estimate the gradient of log-likelihood for kde evaluated 
      at the points of kde2</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>entropyGrad(p)</code></td>
    <td width="77%"><p>estimate gradient of entropy (uses llGrad)</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>miGrad(p,dim)</code></td>
    <td width="77%"><p>estimate gradient for mutual information between p(dim), p(~dim)</p> </td>
  </tr>
  <tr> 
    <td width="23%"><code>klGrad(p1,p2)</code></td>
    <td width="77%"><p>estimate gradient direction of KL-divergence</p></td>
  </tr>
</table>
<p> <b><font size="+1">Mixture products: (NBP stuff) </font></b><font size="+1"><i>(GAUSSIAN 
  KERNELS ONLY)</i></font> </p>
<table width="90%" border="1" cellspacing="0" cellpadding="2">
  <tr> 
    <td colspan="2"><code>productExact</code></td>
    <td width="678"><p>exact computation (N^d kernel centers)</p> </td>
  </tr>
  <tr> 
    <td colspan="2"><code>productApprox</code></td>
    <td width="678"><p>accessor for other product sampling methods</p></td>
  </tr>
  <tr> 
    <td width="20">&nbsp;</td>
    <td width="170"><code>prodSampleExact</code></td>
    <td width="678"><p>sample N points exactly (N^d computation)</p></td>
  </tr>
  <tr> 
    <td width="20">&nbsp;</td>
    <td width="170"><code>prodSampleEpsilon</code></td>
    <td width="678"><p>kd-tree epsilon-exact sampler</p> </td>
  </tr>
  <tr> 
    <td width="20">&nbsp;</td>
    <td width="170"><code>prodSampleGibbs1</code></td>
    <td width="678"><p>seq. index gibbs sampler</p></td>
  </tr>
  <tr> 
    <td width="20">&nbsp;</td>
    <td width="170"><code>prodSampleGibbs2</code></td>
    <td width="678"><p>product of experts gibbs sampler</p></td>
  </tr>
  <tr> 
    <td width="20">&nbsp;</td>
    <td width="170"><code>prodSampleGibbsMS1</code></td>
    <td width="678"><p>multiresolution version of GS1</p> </td>
  </tr>
  <tr> 
    <td width="20">&nbsp;</td>
    <td width="170"><code>prodSampleGibbsMS2</code></td>
    <td width="678"><p>multiresolution version of GS2</p></td>
  </tr>
  <tr> 
    <td width="20">&nbsp;</td>
    <td width="170"><code>prodSampleImportance</code></td>
    <td width="678"><p>&quot;mixture&quot; importance sampling</p></td>
  </tr>
  <tr>
    <td width="20">&nbsp;</td>
    <td width="170"><code>prodSampleImportGauss</code></td>
    <td width="678"><p>gaussian importance sampling</p> </td>
  </tr>
</table>
<p>&nbsp;</p>



<h1> COPYRIGHT / LICENSE </h1>
<p>The kde package and all code were written by Alex Ihler and Mike Mandel, and 
  are copyrighted under the (lesser) GPL: </p>
<blockquote>
  <p>Copyright (C) 2003 Alexander Ihler </p>
</blockquote>
<p>This program is free software; you can redistribute it and/or modify it under 
  the terms of the GNU Lesser General Public License as published by the Free 
  Software Foundation; version 2.1 or later. This program is distributed in the 
  hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied 
  warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU 
  Lesser General Public License for more details. You should have received a copy 
  of the GNU Lesser General Public License along with this program; if not, write 
  to the Free Software Foundation, Inc., 59 Temple Place - Suite 330, Boston, 
  MA 02111-1307, USA. </p>
<p>The authors may be contacted via email at: <i>ihler (at) alum (.) mit (.) edu</i> </p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<h1>CHANGELOG </h1>
<pre>
CHANGE LOG FOR KERNEL DENSITY ESTIMATION CLASS
==============================================

08/14/07   ATI   Fixed 64-bit support for productApprox functions + bugfix
07/16/07   ATI   Fixed 64-bit support for most functions
01/08/04   ATI   Added support for LOO estimate in llGrad; fixed computation
                 of norm. constant for LOO version of evaluate
11/22/04   ATI   Added (original) Fast Gauss Transform (Greengard & Strain '91), 
                 using newer (correct) error bound of Baxter & Roussos '02
11/09/04   ATI   Fixed bug in IFGT eval (incorrect scale factor)
10/02/04   ATI   Added support for Yang, Duraiswami, and Gumerov's Improved Fast
                 Gauss Transform.  Extremely fast; loose bounds on absolute error.
09/17/04   ATI   Fixed permutation bug in adjustBW, and bug in llGrad for evals
                 between two distributions.  Added explicit discrete resampling.
08/04/04   ATI   Updated productApprox:import, reduceKD; added ISE type to reduceKD
07/09/04   ATI   Fixed small bugs: condition.m, jointrees.m, productExact.m
                 Improved speed of sample.m 
02/19/04   ATI   Added "llHess" (Hessian) and "modes" (mode-finding) functions
01/29/04   ATI   fixed 0 vs 1-base err in "index" ret'n values of productApprox
01/22/04   ATI   Added "ise" method and epsilon-exact MEX implementation
                 Fixed bug in epsilon and exact products of variable-BW densities
                 Improved implementation of "condition" for fixed-BW densities
12/28/03   ATI   Removed "abs" KL method, replaced with "ise" estimate method
                 ("abs" was not a good est. of KL but served as an est. of ISE)
12/13/03   ATI   Fixed bug in KNN function and some bugs with the "reduce" f'n & "kld"
                 Added some example demonstration functions
12/05/03   ATI   Added "reduce" function
                 Fixed bug in "productExact" (thanks Chunhua Shen)
                 Fixed bug in adjustBW (caused crashing or termination)
11/18/03   ATI   Added support for additional KL-divergence estimates
10/28/03   ATI   Added support for "kde(pts,'kstype')" constructor
10/24/03   ATI   Fixed an error in "adjustWeights"; added mex & dll files to tarfile
</pre>
<p></p>

</div>

</body>
</html>
