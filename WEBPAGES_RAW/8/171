
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Computational Vision | ICS | UC Irvine</title>
  <link rel="stylesheet" type="text/css" href="/stylesheets/screen.css" media="all">
</head>

<body id="publications">
  <div id="outerframe">
  <div id="header">
    <h1>Computational Vision at UC Irvine &nbsp;<img src="/images/eye_small.jpg" alt="small eye"></h1>
  </div>
  <div id="tabs">
    <ul id="tabnav">
      <li id="home_tab"><a href="/index.html">home</a></li>
      <li id="projects_tab"><a href="/projects.html">projects</a></li>
      <li id="people_tab"><a href="/people.html">people</a></li>
      <li id="publications_tab"><a href="/publications.html">publications</a></li>
      <li id="datasets_tab"><a href="/datasets/index.html">datasets</a></li>
      <li id="events_tab"><a href="/events.html">events</a></li>
      <li id="courses_tab"><a href="/courses.html">courses</a></li>
      <li id="contact_tab"><a href="/contact.html">contact</a></li>
      <li id="links_tab"><a href="/links.html">links</a></li>
    </ul>
  </div>

  <div id="content">
    <div id="paper_title">Articulated Pose Estimation With Tiny Synthetic Videos</div>
    <div id="paper_authors"><a href="/people/29.html">Dennis&nbsp;Park</a>, <a href="/people/20.html">Deva&nbsp;Ramanan</a></div>
    <div id="abstract">
      <img style="float:left;" src="icon_drop.jpg" alt="icon">
      We address the task of articulated pose estimation from
video sequences. We consider an interactive setting where
the initial pose is annotated in the first frame. Our system
synthesizes a large number of hypothetical scenes with
different poses and camera positions by applying geometric
deformations to the first frame. We use these synthetic
images to generate a custom labeled training set for the
video in question. This training data is then used to learn
a regressor (for future frames) that predicts joint locations
from image data. Notably, our training set is so accurate
that nearest-neighbor (NN) matching on low-resolution
pixel features works well. As such, we name our underlying
representation “tiny synthetic videos”. We present quantitative
results the Friends benchmark dataset that suggests
our simple approach matches or exceed state-of-the-art.

    </div>
    <div id="bibtext">
      <h3>Download: <a href="/papers/ParkR_CVPR_2015/ParkR_CVPR_2015.pdf">pdf</a></h3>
      <h3>Text Reference</h3>
Dennis Park and Deva Ramanan.
Articulated pose estimation with tiny synthetic videos.
In <em>The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em>. 2015.<br>
<h3>BibTeX Reference</h3>
@inproceedings{ParkR_CVPR_2015,<br>
&nbsp;&nbsp;&nbsp;&nbsp;author = "Park, Dennis and Ramanan, Deva",<br>
&nbsp;&nbsp;&nbsp;&nbsp;title = "Articulated Pose Estimation With Tiny Synthetic Videos",<br>
&nbsp;&nbsp;&nbsp;&nbsp;booktitle = "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops",<br>
&nbsp;&nbsp;&nbsp;&nbsp;year = "2015"<br>
}<br>
    </div>
  </div>
  <div id="footer">
    <div>
      <a href="/">Computational Vision</a> |
      <a href="http://www.ics.uci.edu/">School of Information and Computer Sciences</a> |
      <a href="http://www.uci.edu/">UC Irvine</a>
    </div>
    <div id="updated">&copy; 2007-2016 UC Irvine</div>
  </div>
  </div>
</body>
</html>

