



<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">
<html>
<head>
<title>UCI Machine Learning Repository: Car Evaluation Data Set: Support</title>

<!-- Stylesheet link -->
<link rel="stylesheet" type="text/css" href="../assets/ml.css" />

<script language="JavaScript" type="text/javascript">
<!--
function checkform ( form )
{
  // see http://www.thesitewizard.com/archive/validation.shtml
  // for an explanation of this script and how to use it on your
  // own website

  // ** START **
  if (form.q.value == "")
  {
    alert( "Please enter search terms." );
    form.q.focus();
    return false ;
  }

  if (getCheckedValue(form.sitesearch) == "ics.uci.edu" && form.q.value.indexOf("site:archive.ics.uci.edu/ml") == -1)
  {
    form.q.value = form.q.value + " site:archive.ics.uci.edu/ml";
  }

  // ** END **
  return true ;
}

// return the value of the radio button that is checked
// return an empty string if none are checked, or
// there are no radio buttons
function getCheckedValue(radioObj) {
	if(!radioObj)
		return "";
	var radioLength = radioObj.length;
	if(radioLength == undefined)
		if(radioObj.checked)
			return radioObj.value;
		else
			return "";
	for(var i = 0; i < radioLength; i++) {
		if(radioObj[i].checked) {
			return radioObj[i].value;
		}
	}
	return "";
}
//-->
</script>

</head>

<body>


<!-- SITE HEADER (INCLUDES LOGO AND SEARCH BOX) -->

<table width=100% bgcolor="#003366">
<tr>
	<td>
		<span class="normal"><a href="../index.html" 
alt="Home"><img src="../assets/logo.gif" 
border=0></img></a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://cml.ics.uci.edu"><font color="FFDD33">Center for Machine Learning and Intelligent Systems</font></a></span>
	</td>
	<td width=100% valign=top align="right">
		<span class="whitetext">
		<a href="../about.html">About</a>&nbsp;
		<a href="../citation_policy.html">Citation Policy</a>&nbsp;
		<a href="../donation_policy.html">Donate a Data Set</a>&nbsp;
		<a href="../contact.html">Contact</a>
		</span>

		<br>
		<br>
		<!-- Search Google -->

		<FORM method=GET action=http://www.google.com/custom onsubmit="return checkform(this);">
		<INPUT TYPE=text name=q size=30 maxlength=255 value="">
		<INPUT type=submit name=sa VALUE="Search">
		<INPUT type=hidden name=cof VALUE="AH:center;LH:130;L:http://archive.ics.uci.edu/assets/logo.gif;LW:384;AWFID:869c0b2eaa8d518e;">
		<input type=hidden name=domains value="ics.uci.edu">
		<br>
		<input type=radio name=sitesearch value="ics.uci.edu" checked> <span class="whitetext"><font size="1">Repository</font></span>
		<input type=radio name=sitesearch value=""> <span class="whitetext"><font size="1">Web</font></span>
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
		<A HREF=http://www.google.com/search><IMG SRC=http://www.google.com/logos/Logo_25blk.gif border=0 ALT=Google align=middle height=27></A>
		<br>
		</FORM>
		<!-- Search Google -->


		<span class="whitetext"><a href="../datasets.html"><font size="3" color="#FFDD33"><b>View ALL Data Sets</b></font></a></span>
		<br>
	</td>
</tr>
</table>

<br />
<table width=100% border=0 cellpadding=2><tr><td>


   <table><tr>
     <td valign=top>
	<p>
	<span class="heading"><b>Car Evaluation Data Set</b></span>

		
		<img src="../assets/MLimages/Large19.jpg" hspace=20 vspace=10 align=right />		<p class="normal">Below are papers that cite this data set, with context shown.
		Papers were automatically harvested and associated with this data set, in collaboration with <a href="http://rexa.info">Rexa.info</a>.</p>
		<img src="../assets/rexa.jpg" />
		<p class="normal"><a href="/ml/datasets/Car+Evaluation">Return to Car Evaluation data set page</a>.
		<hr><p class="normal"><a name="8e674b6eff0f726ba6fff46ef6eaff968dc89f39"></a><i>Qingping Tao Ph. D. <a href="http://rexa.info/paper/8e674b6eff0f726ba6fff46ef6eaff968dc89f39">MAKING EFFICIENT LEARNING ALGORITHMS WITH EXPONENTIALLY MANY FEATURES</a>. Qingping Tao A DISSERTATION Faculty of The Graduate College University of Nebraska In Partial Fulfillment of Requirements. 2004. </i><br><br>(T 0 = n 2 and T s =10n 2 ). M - Metropolis, G - Gibbs, MG - Metropolized Gibbs, PT - Parallel Tempering, BF - Brute Force. Data Sets iris <b>car</b> breast cancer voting auto annealing n 4 6 9 16 25 38 M 5.3 � 2.1 1.7 � 0.831.5 � 5.05.0� 2.1 12.8 � 7.5 1.0 � 0.7 G 6.7 � 3.81.9 � 0.8 30.9 � 5.5 5.0 � 2.415.6 � 7.80.6 � 0.5 MG 6.0 � 1.7<br></p><hr><p class="normal"><a name="f14d3edaeac2280dc4e49948d9d0fc1159bd05ca"></a><i>Daniel J. Lizotte and Omid Madani and Russell Greiner. <a href="http://rexa.info/paper/f14d3edaeac2280dc4e49948d9d0fc1159bd05ca">Budgeted Learning of Naive-Bayes Classifiers</a>. UAI. 2003. </i><br><br>at 50 purchases is better than its performance at 50 when the budget is set at 300. Other policies do not take the budget into account. We have observed the same overall patterns on several other datasets that we have tested the policies on so far  <b>CAR</b>  DIABETES, CHESS, BREAST): the performance of SFL is superior or comparable to the performance of other policies, and Biased-Robin is the best<br></p><hr><p class="normal"><a name="14f025e969e3a0418fd852ee46e54039ab3f216a"></a><i>Jianbin Tan and David L. Dowe. <a href="http://rexa.info/paper/14f025e969e3a0418fd852ee46e54039ab3f216a">MML Inference of Decision Graphs with Multi-way Joins and Dynamic Attributes</a>. Australian Conference on Artificial Intelligence. 2003. </i><br><br>- giving a total 10x10=100 tests. <b>car</b> Evaluation data set: The <b>car evaluation</b> data set from the UCI repository [1] was generated from an underlying decision tree model. There are 1728 instances with four output classes in the set. Each data item has 6<br></p><hr><p class="normal"><a name="1b77c2b6fd8a261af286cf411879f9f520824bd6"></a><i>Marc Sebban and Richard Nock and St�phane Lallich. <a href="http://rexa.info/paper/1b77c2b6fd8a261af286cf411879f9f520824bd6">Stopping Criterion for Boosting-Based Data Reduction Techniques: from Binary to Multiclass Problem</a>. Journal of Machine Learning Research, 3. 2002. </i><br><br>(Balance, Echocardiogram, German, Horse Colic, Led, Pima and Vehicle) see important improvements, ranging from 1% to } 5%. In contrast, only one dataset sees significant accuracy decrease  <b>Car</b>  96.0% vs. 93.9%). 9. Conclusions and Future Research This paper explores a method for prototype selection based on boosting, and gives statistical criteria<br></p><hr><p class="normal"><a name="5193dfc0a9d39b5f86fe360d6beff81aa9b7390e"></a><i>Nikunj C. Oza and Stuart J. Russell. <a href="http://rexa.info/paper/5193dfc0a9d39b5f86fe360d6beff81aa9b7390e">Experimental comparisons of online and batch versions of bagging and boosting</a>. KDD. 2001. </i><br><br>for which we ran the bagging and boosting algorithms with decision trees was the <b>Car</b> Evaluation dataset from the UCI Repository. Figure 5 shows the learning curve. Batch and online bagging with decision trees perform almost identically (and always significantly better than a single decision tree).<br></p><hr><p class="normal"><a name="bc80295973a43d3806ff4dfe83e5724260301c33"></a><i>Iztok Savnik and Peter A. Flach. <a href="http://rexa.info/paper/bc80295973a43d3806ff4dfe83e5724260301c33">Discovery of multivalued dependencies from relations</a>. Intell. Data Anal, 4. 2000. </i><br><br>which were used in the experiments are available at UCI Machine learning repository [10]. In the case of the datasets <b>Car</b>  Bupa and Abalone we use randomly selected subsets of the original datasets. For each experiment we specify the name of the relation (dataset) r(R), the number of tuples in relation jrj, the<br></p><hr><p class="normal"><a name="d2ad474fa4c9b346e9ac8f41900cea7d4917c7ac"></a><i>Marc Sebban and Richard Nock and Jean-Hugues Chauchat and Ricco Rakotomalala. <a href="http://rexa.info/paper/d2ad474fa4c9b346e9ac8f41900cea7d4917c7ac">Impact of learning set quality and size on decision tree performances</a>. Int. J. Comput. Syst. Signal, 1. 2000. </i><br><br>in detail. Actually, we note that for 3 datasets  <b>Car</b>  Pima and Xd6),thedecisiontreeisso reduced that no rule is induced, resulting in a decision rule in favor of the majority class in LS. This explains why accuracy falls much, respectively<br></p><hr><p class="normal"><a name="47354ca48da5014e0a8f5e4da7f3a7e9aaa6e9e5"></a><i>Jie Cheng and Russell Greiner. <a href="http://rexa.info/paper/47354ca48da5014e0a8f5e4da7f3a7e9aaa6e9e5">Comparing Bayesian Network Classifiers</a>. UAI. 1999. </i><br><br>person makes over 50K a year. The discretization process ignores "fnlwgt" (which is one of the 14 attributes). We therefore omit "flnwgt" and use the remainder 13 attributes in our experiments. <b>car</b> dataset: <b>car evaluation</b> based on the six features of a car. Chess: chess end-game result classification based on board-descriptions. Flare: classifying the number of times of occurrence of certain type of<br></p><hr><p class="normal"><a name="7e787ada7263180d2a9bad6a3c490e7f8b0d4cd0"></a><i>Daniel J. Lizotte and Omid Madani and Russell Greiner. <a href="http://rexa.info/paper/7e787ada7263180d2a9bad6a3c490e7f8b0d4cd0">Budgeted Learning, Part II: The Na#ve-Bayes Case</a>. Department of Computing Science University of Alberta. </i><br><br>SFL at 50 queries is better than its performance at 50 when the budget is set at 300. Other policies do not take the budget into account. We have observed the same overall patterns on several other datasets that we have tested the policies so far  <b>CAR</b>  DIABETES, CHESS, BREAST): the performance of SFL is superior or comparable to the performance of other policies, and BIASED ROBIN is the best algorithm<br></p><hr><p class="normal"><a name="8f5ae7219e74a85e3f722b58b3fedb30eab7a1d7"></a><i>Huan Liu. <a href="http://rexa.info/paper/8f5ae7219e74a85e3f722b58b3fedb30eab7a1d7">A Family of Efficient Rule Generators</a>. Department of Information Systems and Computer Science National University of Singapore. </i><br><br>Equipped with the above two evaluation measures, we can conduct some experiments to empirically compare the four versions of rule generators, and with other known methods [13, 22]. A. Method One data set - <b>CAR</b> will be used to show the differences between the versions of our rule generator, and to compare with the results reported in [22] since they have done some comparison with other methods such<br></p><hr><p class="normal"><a name="6aae20aa5fd96e903634bb73244782652cd4e947"></a><i>Zhiqiang Yang and Sheng Zhong and Rebecca N. Wright. <a href="http://rexa.info/paper/6aae20aa5fd96e903634bb73244782652cd4e947">Privacy-Preserving Classification of Customer Data without Loss of Accuracy</a>. Computer Science Department, Stevens Institute of Technology. </i><br><br>of size d, then the number of joint frequencies that need to be counted is exponential in m. In some cases we have small m and d and thus we can still achieve reasonable overhead. For example, the data set of <b>Car</b> Evaluation Database from UCI repository [BM98] has six nominal attributes: buying, maint, doors, persons, lug boot and safety, and the class attribute has a domain of size four. For such 9 a<br></p><hr><p class="normal"><a name="80d25f1152aed1f55fc47bd0f450312debe7617e"></a><i>Jos'e L. Balc'azar. <a href="http://rexa.info/paper/80d25f1152aed1f55fc47bd0f450312debe7617e">Rules with Bounded Negations and the Coverage Inference Scheme</a>. Dept. LSI, UPC. </i><br><br>is analyzed and proved to have reasonable algebraic properties; and examples are given where, from a single rule, many other rules can be found through this scheme. 3. Experiments The <b>Car</b> Evaluation Dataset [BR] in the UCI repository [BM] has seven categorical columns (six attributes and a class), which we preprocessed into a single boolean attribute per value of each categorical attribute, thus<br></p><hr><p class="normal"><a name="e2e72927eb590e2b7daf9095e42d6ed43ce21e68"></a><i>Shi Zhong and Weiyu Tang and Taghi M. Khoshgoftaar. <a href="http://rexa.info/paper/e2e72927eb590e2b7daf9095e42d6ed43ce21e68">Boosted Noise Filters for Identifying Mislabeled Data</a>. Department of Computer Science and Engineering Florida Atlantic University. </i><br><br>in Table 1. Overall, BBF-I significantly outperforms BBF-II, except for low ( 20%) noise levels for the adult, <b>car</b>  and nursery datasets. The reason BBF-II performs poorly may be that too many clean instances are weighted low. The noise filter constructed in the next round loses strong support from clean data instances, which are<br></p><hr><p class="normal"><a name="4fe77f0de67f4dda7e7174b944840d4d49fe15ac"></a><i>Hyunwoo Kim and Wei-Yin Loh. <a href="http://rexa.info/paper/4fe77f0de67f4dda7e7174b944840d4d49fe15ac">Classification Trees with Bivariate Linear Discriminant Node Models</a>. Department of Statistics Department of Statistics University of Tennessee University of Wisconsin. </i><br><br>maximum simplification, where the root node is not split. The second example shows how collinearity among predictors can creates difficulties for other classification tree methods. 4.1 <b>Car</b> Data This data set is from Lock (1993). It contains specifications for 93 new car models for the 1993 year. We use the type of car (small, sporty, compact, midsize, large, and van) as the class variable. The predictor<br></p><hr><p class="normal"><a name="217beab6a7a7b64dc929c3c5fdb42e812f8b2431"></a><i>Daniel J. Lizotte. <a href="http://rexa.info/paper/217beab6a7a7b64dc929c3c5fdb42e812f8b2431">Library Release Form Name of Author</a>. Budgeted Learning of Naive Bayes Classifiers. </i><br><br>than when it is assumed to be 300 (i.e., when it looks ahead farther than it should). Other policies do not take the budget into account. We have observed the same overall patterns on several other datasets that we have tested the policies on so far  <b>CAR</b>  DIABETES, CHESS, BREAST): the performance of SFL is superior or comparable to the performance of other policies, and Biased-Robin is the best 36<br></p><hr><p class="normal"><a name="3e9ebff12a232c9f091156827e92c55d259b95f3"></a><i>Nikunj C. Oza and Stuart J. Russell. <a href="http://rexa.info/paper/3e9ebff12a232c9f091156827e92c55d259b95f3">Online Bagging and Boosting</a>. Computer Science Division University of California. </i><br><br>ITI online algorithm [14]; batch and online Naive Bayes algorithms are essentially identical. To illustrate the convergence of batch and online learning, we experimented with the <b>Car</b> Evaluation dataset from the UCI Machine Learning Repository [2]. The dataset has 1728 examples, of which we retained 346 (20%) as a test set and used 200, 400, 600, 800, 1000, 1200, and all the remaining 1382 examples<br></p>


	</td></tr></table>



<hr>

<p class="normal"><a href="/datasets/Car+Evaluation">Return to Car Evaluation data set page</a>.


<table cellpadding=5 align=center><tr valign=center>
		<td><p class="normal">Supported By:</p></td>
        <td><img src="../assets/nsfe.gif" height=60 /> </td>
        <td><p class="normal">&nbsp;In Collaboration With:</p></td>
        <td><img src="../assets/rexaSmall.jpg" /></td>
</tr></table>

<center>
<span class="normal">
<a href="../about.html">About</a>&nbsp;&nbsp;||&nbsp;
<a href="../citation_policy.html">Citation Policy</a>&nbsp;&nbsp;||&nbsp;
<a href="../donation_policy.html">Donation Policy</a>&nbsp;&nbsp;||&nbsp;
<a href="../contact.html">Contact</a>&nbsp;&nbsp;||&nbsp;
<a href="http://cml.ics.uci.edu">CML</a>
</span>
</center>




</body>
</html>
