
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Computational Vision | ICS | UC Irvine</title>
  <link rel="stylesheet" type="text/css" href="/stylesheets/screen.css" media="all">
</head>

<body id="publications">
  <div id="outerframe">
  <div id="header">
    <h1>Computational Vision at UC Irvine &nbsp;<img src="/images/eye_small.jpg" alt="small eye"></h1>
  </div>
  <div id="tabs">
    <ul id="tabnav">
      <li id="home_tab"><a href="/index.html">home</a></li>
      <li id="projects_tab"><a href="/projects.html">projects</a></li>
      <li id="people_tab"><a href="/people.html">people</a></li>
      <li id="publications_tab"><a href="/publications.html">publications</a></li>
      <li id="datasets_tab"><a href="/datasets/index.html">datasets</a></li>
      <li id="events_tab"><a href="/events.html">events</a></li>
      <li id="courses_tab"><a href="/courses.html">courses</a></li>
      <li id="contact_tab"><a href="/contact.html">contact</a></li>
      <li id="links_tab"><a href="/links.html">links</a></li>
    </ul>
  </div>

  <div id="content">
    <div id="paper_title">Parsing videos of actions with segmental grammars</div>
    <div id="paper_authors"><a href="/people/28.html">Hamed&nbsp;Pirsiavash</a>, <a href="/people/20.html">Deva&nbsp;Ramanan</a></div>
    <div id="abstract">
      <img style="float:left;" src="icon_drop.jpg" alt="icon">
      Real-world videos of human activities exhibit temporal
structure at various scales; long videos are typically composed
out of multiple action instances, where each instance
is itself composed of sub-actions with variable durations
and orderings. Temporal grammars can presumably model
such hierarchical structure, but are computationally difficult
to apply for long video streams. We describe simple
grammars that capture hierarchical temporal structure
while admitting inference with a finite-state-machine. This
makes parsing linear time, constant storage, and naturally
online. We train grammar parameters using a latent structural
SVM, where latent subactions are learned automatically.
We illustrate the effectiveness of our approach over
common baselines on a new half-million frame dataset of
continuous YouTube videos.

    </div>
    <div id="bibtext">
      <h3>Download: <a href="/papers/PirsiavashR_CVPR_2014/PirsiavashR_CVPR_2014.pdf">pdf</a></h3>
      <h3>Text Reference</h3>
Hamed Pirsiavash and Deva Ramanan.
Parsing videos of actions with segmental grammars.
In <em>Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on</em>, 612â€“619. IEEE, 2014.<br>
<h3>BibTeX Reference</h3>
@inproceedings{PirsiavashR_CVPR_2014,<br>
&nbsp;&nbsp;&nbsp;&nbsp;author = "Pirsiavash, Hamed and Ramanan, Deva",<br>
&nbsp;&nbsp;&nbsp;&nbsp;title = "Parsing videos of actions with segmental grammars",<br>
&nbsp;&nbsp;&nbsp;&nbsp;booktitle = "Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on",<br>
&nbsp;&nbsp;&nbsp;&nbsp;pages = "612--619",<br>
&nbsp;&nbsp;&nbsp;&nbsp;year = "2014",<br>
&nbsp;&nbsp;&nbsp;&nbsp;organization = "IEEE"<br>
}<br>
    </div>
  </div>
  <div id="footer">
    <div>
      <a href="/">Computational Vision</a> |
      <a href="http://www.ics.uci.edu/">School of Information and Computer Sciences</a> |
      <a href="http://www.uci.edu/">UC Irvine</a>
    </div>
    <div id="updated">&copy; 2007-2016 UC Irvine</div>
  </div>
  </div>
</body>
</html>

