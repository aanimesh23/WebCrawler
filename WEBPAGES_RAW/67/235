<!DOCTYPE html 
    PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
  <title>SLI | Classes / CS274A: Probabilistic Learning </title>
  <meta http-equiv='Content-Style-Type' content='text/css' />
  <link rel='stylesheet' href='http://sli.ics.uci.edu/pmwiki/pub/skins/custom/pmwiki.css' type='text/css' />
  <!--HTMLHeader--><style type='text/css'><!--
  ul, ol, pre, dl, p { margin-top:0px; margin-bottom:0px; }
  code.escaped { white-space: nowrap; }
  .vspace { margin-top:1.33em; }
  .indent { margin-left:40px; }
  .outdent { margin-left:40px; text-indent:-40px; }
  a.createlinktext { text-decoration:none; border-bottom:1px dotted gray; }
  a.createlink { text-decoration:none; position:relative; top:-0.5em;
    font-weight:bold; font-size:smaller; border-bottom:none; }
  img { border:0px; }
  .editconflict { color:green; 
  font-style:italic; margin-top:1.33em; margin-bottom:1.33em; }

  table.markup { border:2px dotted #ccf; width:90%; }
  td.markup1, td.markup2 { padding-left:10px; padding-right:10px; }
  table.vert td.markup1 { border-bottom:1px solid #ccf; }
  table.horiz td.markup1 { width:23em; border-right:1px solid #ccf; }
  table.markup caption { text-align:left; }
  div.faq p, div.faq pre { margin-left:2em; }
  div.faq p.question { margin:1em 0 0.75em 0; font-weight:bold; }
  div.faqtoc div.faq * { display:none; }
  div.faqtoc div.faq p.question 
    { display:block; font-weight:normal; margin:0.5em 0 0.5em 20px; line-height:normal; }
  div.faqtoc div.faq p.question * { display:inline; }
   
    .frame 
      { border:1px solid #cccccc; padding:4px; background-color:#f9f9f9; }
    .lfloat { float:left; margin-right:0.5em; }
    .rfloat { float:right; margin-left:0.5em; }
a.varlink { text-decoration:none;}

--></style>  <meta name='robots' content='index,follow' />

</head>
<body>
<!--PageHeaderFmt-->
  <div id='wikilogo'><a href='http://sli.ics.uci.edu'><img src='/pmwiki/pub/skins/custom/SLI_white.png'
    alt='SLI' border='0' /></a></div>
  <div id='wikihead'>
  <form action='http://sli.ics.uci.edu'>
    <!-- <span class='headnav'><a href='http://sli.ics.uci.edu/Classes/RecentChanges'
      accesskey='c'>Recent Changes</a> -</span> --> 
    <input type='hidden' name='n' value='Classes.2008S' />
    <input type='hidden' name='action' value='search' />
    <!-- <a href='http://sli.ics.uci.edu/Site/Search'>Search</a>: -->
    <input type='text' name='q' value='' class='inputbox searchbox' />
    <input type='submit' class='inputbutton searchbutton'
      value='Search' />
    <a href='http://sli.ics.uci.edu/Site/Search'>(?)</a>
  </form></div>
<!--/PageHeaderFmt-->
  <table id='wikimid' width='100%' cellspacing='0' cellpadding='0'><tr>
<!--PageLeftFmt-->
      <td id='wikileft' valign='top'>
        <ul><li><a class='wikilink' href='http://sli.ics.uci.edu/Classes/Classes'>Classes</a>
</li><li><a class='wikilink' href='http://sli.ics.uci.edu/Group/Group'>Group</a>
</li><li><a class='wikilink' href='http://sli.ics.uci.edu/Projects/Projects'>Research</a>
</li><li><a class='urllink' href='http://www.ics.uci.edu/~ihler/pubs.html' rel='nofollow'>Publications</a>
</li><li><a class='wikilink' href='http://sli.ics.uci.edu/Code/Code'>Code</a>
</li></ul><div class='vspace'></div><hr />
<div class='vspace'></div>
</td>
<!--/PageLeftFmt-->
      <td id='wikibody' valign='top'>
<!--PageActionFmt-->
        <div id='wikicmds'><ul><li class='browse'><a class='wikilink' href='http://sli.ics.uci.edu/Classes/2008S?action=login'>login</a>
</li></ul>
</div>
<!--PageTitleFmt-->
        <div id='wikititle'>
          <div class='pagegroup'><a href='http://sli.ics.uci.edu/Classes'>Classes</a> /</div>
          <h1 class='pagetitle'>CS274A: Probabilistic Learning</h1></div>
<!--PageText-->
<div id='wikitext'>
<div class='Work' style='float:right; padding:5px; border:2px solid black; background-color:#cccc99' >
<p><span style='font-size:144%'><strong>Assignments and Exams:</strong></span>
</p>
<table border='0' cellspacing='3' ><tr ><td  align='left'><a class='urllink' href='http://sli.ics.uci.edu/Classes/2008S?action=download&amp;upname=hw1.pdf' rel='nofollow'>HW 1</a></td><td >&nbsp;</td><td  align='left'>Due 4/8/08</td><td >&nbsp;</td><td  align='right'><a rel='nofollow' class='createlinktext' href='http://sli.ics.uci.edu/Classes/2008S?action=upload&amp;upname=hw1_solns.pdf'>Solutions</a><a rel='nofollow' class='createlink' href='http://sli.ics.uci.edu/Classes/2008S?action=upload&amp;upname=hw1_solns.pdf'>&nbsp;&Delta;</a></td></tr>
<tr ><td  align='left'><a class='urllink' href='http://sli.ics.uci.edu/Classes/2008S?action=download&amp;upname=hw2.pdf' rel='nofollow'>HW 2</a></td><td >&nbsp;</td><td  align='left'>Due 4/24/08</td><td >&nbsp;</td><td  align='right'><a rel='nofollow' class='createlinktext' href='http://sli.ics.uci.edu/Classes/2008S?action=upload&amp;upname=hw2_solns.pdf'>Solutions</a><a rel='nofollow' class='createlink' href='http://sli.ics.uci.edu/Classes/2008S?action=upload&amp;upname=hw2_solns.pdf'>&nbsp;&Delta;</a></td></tr>
<tr ><td  align='left'><a rel='nofollow' class='createlinktext' href='http://sli.ics.uci.edu/Classes/2008S?action=upload&amp;upname=midterm.pdf'>Midterm</a><a rel='nofollow' class='createlink' href='http://sli.ics.uci.edu/Classes/2008S?action=upload&amp;upname=midterm.pdf'>&nbsp;&Delta;</a></td><td >&nbsp;</td><td  align='left'>Class 5/1/08</td><td >&nbsp;</td><td  align='right'><a rel='nofollow' class='createlinktext' href='http://sli.ics.uci.edu/Classes/2008S?action=upload&amp;upname=midterm_solns.pdf'>Solutions</a><a rel='nofollow' class='createlink' href='http://sli.ics.uci.edu/Classes/2008S?action=upload&amp;upname=midterm_solns.pdf'>&nbsp;&Delta;</a></td></tr>
<tr ><td  align='left'><a class='urllink' href='http://sli.ics.uci.edu/Classes/2008S?action=download&amp;upname=hw3.pdf' rel='nofollow'>HW 3</a>, <a rel='nofollow' class='createlinktext' href='http://sli.ics.uci.edu/Classes/2008S?action=upload&amp;upname=hw3.mat'>Data</a><a rel='nofollow' class='createlink' href='http://sli.ics.uci.edu/Classes/2008S?action=upload&amp;upname=hw3.mat'>&nbsp;&Delta;</a></td><td >&nbsp;</td><td  align='left'>Due 5/22/08</td><td >&nbsp;</td><td  align='right'><a rel='nofollow' class='createlinktext' href='http://sli.ics.uci.edu/Classes/2008S?action=upload&amp;upname=hw3_solns.pdf'>Solutions</a><a rel='nofollow' class='createlink' href='http://sli.ics.uci.edu/Classes/2008S?action=upload&amp;upname=hw3_solns.pdf'>&nbsp;&Delta;</a></td></tr>
<tr ><td  align='left'><a class='urllink' href='http://sli.ics.uci.edu/Classes/2008S?action=download&amp;upname=hw4.pdf' rel='nofollow'>HW 4</a>, <a rel='nofollow' class='createlinktext' href='http://sli.ics.uci.edu/Classes/2008S?action=upload&amp;upname=hw4.mat'>Data</a><a rel='nofollow' class='createlink' href='http://sli.ics.uci.edu/Classes/2008S?action=upload&amp;upname=hw4.mat'>&nbsp;&Delta;</a></td><td >&nbsp;</td><td  align='left'>Due 6/05/08</td><td >&nbsp;</td><td >&nbsp;</td></tr>
<tr ><td  align='left'>Final</td><td >&nbsp;</td><td  align='left'>Class 6/12/08</td><td >&nbsp;</td><td >&nbsp;</td></tr>
<tr ><td >&nbsp;</td><td >&nbsp;</td><td >&nbsp;</td><td >&nbsp;</td><td >&nbsp;</td></tr>
<tr ><td  align='right' colspan='5'>Student Comment Page</td></tr>
</table></div>
<div class='vspace'></div><h3>Introduction to probabilistic models, inference, and learning.</h3>
<p>CS274A is an introductory course to probabilistic approaches to learning from data. Probabilistic models form an important part of many areas of computer science, and probabilistic learning (in this context, automatically constructing probabilistic models from data) has become an important tool in sub-fields such as artificial intelligence, data mining, speech recognition, computer vision, bioinformatics, signal processing, and many more. CS274A will provide an introduction to the concepts and principles which underly probabilistic models, and apply these principles to the development, analysis, and practical application of machine learning algorithms.
</p>
<p class='vspace'>The course will focus primarily on parametric probabilistic modeling, including data likelihood, parameter estimation using likelihood and Bayesian approaches, hypothesis testing and classification problems, density estimation, clustering, and regression. Related problems, including model selection, overfitting, and bias/variance trade-offs will also be discussed.
</p>
<div class='vspace'></div><h3>Background. </h3>
<p>The course is intended to be an introduction to probabilistic learning, and thus has few explicit requirements. Students are expected to be familiar with basic concepts from probability, linear algebra, multivariate calculus, etc. Homeworks will use the MATLAB programming environment, but no prior experience with MATLAB is required for the course.
</p>
<div class='vspace'></div><h3>Course format. </h3>
<p>Two lectures per week. Homeworks due <strong>in class</strong> approximately every two weeks. Two exams (midterm and final). Grading: 40% homework, 30% midterm, 30% final.
</p>
<div class='vspace'></div><h3>Office Hours.</h3>
<p>Office hours for the course are Monday 12-1pm and 2-3pm, or by appointment.
</p>
<div class='vspace'></div><h3>Collaboration.</h3>
<p>Discussion of the course concepts and methods among the students is encouraged; however, all work handed in should be completely your own.  In order to strike a balance, we'll use the "work product" rule: while discussing anything related to the homework, you should retain no work product created during the discussion.  In other words, you can meet and discuss the problems, describe the solution, etc., but then all parties must go away from the meeting with no record (written notes, code, etc.) from the meeting and do the homework problem on your own.  If you work on a whiteboard, just erase it when you're done discussing.  Don't show someone else your homework, or refer to it during the discussion, since by this policy you must then throw it away.
</p>
<div class='vspace'></div><h3>Textbooks. </h3>
<p>The required textbook for the course is Bishop's "Pattern Recognition and Machine Learning", but lectures are likely to follow the book only loosly. Other recommended reading include MacKay's "Information Theory, Inference, and Learning Algorithms" (available online at <a class='urllink' href='http://www.inference.phy.cam.ac.uk/mackay/itila/' rel='nofollow'>http://www.inference.phy.cam.ac.uk/mackay/itila/</a>), Duda, Hart, and Stork's "Pattern Classification", and Hastie, Tibshirani, and Friedman's "Elements of Statistical Learning".
</p>
<div class='vspace'></div><h3>Matlab</h3>
<p>Often we will write code for the course using the <a class='urllink' href='http://www.mathworks.com' rel='nofollow'>Matlab</a> environment.  Matlab is accessible through NACS computers at several campus locations (e.g., 
<a class='urllink' href='http://www.nacs.uci.edu/computing/labs/mstb210-details.html' rel='nofollow'>MSTB-A</a>, 
<a class='urllink' href='http://www.nacs.uci.edu/computing/labs/mstb226-details.html' rel='nofollow'>MSTB-B</a>), and if you want a copy for yourself student licenses are fairly inexpensive ($100).  Personally, I do not recommend the open-source Octave program as a replacement, as the syntax is not 100% compatible and may cause problems (for me or you).  
</p>
<p class='vspace'>If you are not familiar with Matlab, there are a number of tutorials on the web:
</p><ul><li><a class='urllink' href='http://www.math.utah.edu/lab/ms/matlab/matlab.html' rel='nofollow'>University of Utah</a>, very short
</li><li><a class='urllink' href='http://www.engin.umich.edu/group/ctm/basic/basic.html' rel='nofollow'>CMU / UMichigan tutorial</a>, also short
</li><li><a class='urllink' href='http://www.math.ufl.edu/help/matlab-tutorial/' rel='nofollow'>University of Florida's tutorial</a>, more complete
</li><li><a class='urllink' href='http://www.cyclismo.org/tutorial/matlab/' rel='nofollow'>Union College / Cyclismo.Org tutorial</a>, also good
</li><li><a class='urllink' href='http://www.glue.umd.edu/%7Ensw/ench250/matlab.htm' rel='nofollow'>UMaryland guide</a>, lots of pointers to other tutorials and reference manuals
</li></ul><p>You may want to start with one of the very short tutorials, then use the longer ones as a reference during the rest of the term.
</p>
<div class='vspace'></div><h3>(Tentative) Schedule of Topics.</h3>
<table border='0' cellspacing='10' ><tr ><td  align='left'>Week 1</td><td  align='left'>04/01/2008</td><td  align='left'>Introduction, probability distributions, Bayes' rule</td><td >Suggested reading: <a class='urllink' href='http://www.ics.uci.edu/~smyth/courses/ics274/notes1.pdf' rel='nofollow'>Notes</a> on probability by Prof. Smyth; Bishop, Sec 1.2 &amp; Ch. 2</td></tr>
<tr ><td >&nbsp;</td><td  align='left'>04/03/2008</td><td  align='left'>multivariate distributions, Bayes' nets</td><td >Smyth <a class='urllink' href='http://www.ics.uci.edu/~smyth/courses/ics274/notes2.pdf' rel='nofollow'>notes</a> on multivariate distributions; Bishop Ch. 8</td></tr>
<tr ><td  align='left'>Week 2</td><td  align='left'>04/08/2008</td><td >Markov random fields; introduction to learning, likelihood, parameters</td><td >Bishop Ch. 8</td></tr>
<tr ><td >&nbsp;</td><td  align='left'>04/10/2008</td><td >Class cancelled</td></tr>
<tr ><td  align='left'>Week 3</td><td  align='left'>04/15/2008</td><td  align='left'>Bias/variance; maximum likelihood learning; exponential family, univariate</td><td >Bishop 3.2, 2.4.1, 1.2.4</td></tr>
<tr ><td >&nbsp;</td><td  align='left'>04/17/2008</td><td >ML learning I: multivariate models</td></tr>
<tr ><td  align='left'>Week 4</td><td  align='left'>04/22/2008</td><td >Bayesian learning I: priors, posterior distributions; MAP estimates</td></tr>
<tr ><td >&nbsp;</td><td  align='left'>04/24/2008</td><td >Bayesian learning II: conjugate prior distributions</td></tr>
<tr ><td  align='left'>Week 5</td><td  align='left'>04/29/2008</td><td >Summary and review</td></tr>
<tr ><td >&nbsp;</td><td  align='left'>05/01/2008</td><td >MIDTERM EXAM</td></tr>
<tr ><td  align='left'>Week 6</td><td  align='left'>05/06/2008</td><td  align='left'>Regression I: linear regression</td><td >Bishop Ch 3</td></tr>
<tr ><td >&nbsp;</td><td  align='left'>05/08/2008</td><td  align='left'>Regression II: priors, logistic regression</td><td >Bishop 3, 4.2-3</td></tr>
<tr ><td  align='left'>Week 7</td><td  align='left'>05/13/2008</td><td >More on regression and classification</td></tr>
<tr ><td >&nbsp;</td><td  align='left'>05/15/2008</td><td >Classification and density estimation</td></tr>
<tr ><td  align='left'>Week 8</td><td  align='left'>05/20/2008</td><td >Mixture models and EM: mixtures of Gaussians; k-means; EM</td></tr>
<tr ><td >&nbsp;</td><td  align='left'>05/22/2008</td><td >Mixture models and EM: more on expectation-maximization</td></tr>
<tr ><td  align='left'>Week 9</td><td  align='left'>05/27/2008</td><td  align='left'>Learning in graphical models I: forward-backward, EM</td></tr>
<tr ><td >&nbsp;</td><td  align='left'>05/29/2008</td><td  align='left'>Learning in graphical models II: iterative fitting</td></tr>
<tr ><td >Week 10</td><td  align='left'>06/03/2008</td><td >Additional topics: TBD</td></tr>
<tr ><td >&nbsp;</td><td  align='left'>06/05/2008</td><td >Additional topics: TBD</td></tr>
<tr ><td  align='left'><strong>Final Exam</strong></td><td  align='left'>06/12/2008</td><td >In class final exam, 1:30-3:30pm</td></tr>
</table>
<div class='vspace'></div>
</div>

      </td>
    </tr></table>
<!--PageFooterFmt-->
  <div id='wikifoot'>
    <div class='footnav' style='float:left'> Last modified February 13, 2017, at 02:18 PM</div>
    <div class='footnav' style='float:right; text-align:right'>
    <a href="http://www.ics.uci.edu">Bren School of Information and Computer Science</a><br>
    <a href="http://www.uci.edu">University of California, Irvine</a>
    </div>
  </div>
<!--HTMLFooter--><script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(["_setAccount", "UA-24148957-2"]);
	_gaq.push(["_trackPageview"]);
	(function() {
	  var ga = document.createElement("script"); ga.type = "text/javascript"; ga.async = true;
	  ga.src = ("https:" == document.location.protocol ? "https://ssl" : "http://www") + ".google-analytics.com/ga.js";
	  var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(ga, s);
	  })();
</script>
</body>
</html>
