<h2> Discussion topics </h2>
  <ol>
    <li> Introduction to class format and informal discussion of intelligence.
    <li> <b>1950</b> <i>Can A Machine Think </i>in Computing Machinery and Intelligence by Alan
    Turing.  Poses the problem of deciding whether an
    artifact can exhibit intelligence.
    <li><b>1950</b> <i>Chess Playing Programs and the Problem of Complexity</i> by
    Allen Newell, J Shaw, and Herbert Simon.  Can programs play difficult games well? Discusses
    approaches to game playing, including minimax, static
    evaluation, quiescence, and goals. Does this demonstrate intelligence? What else might be needed? How hard is chess?
    
    <li> <b>1956</b> <i>Realization of a Geometry-theorem Proving Machine</i>
    by H. Gelernter.  Mathematical ability is often thought of as sign of intelligence. Can programs prove theorems? Presents theorem proving as a search
    through a space of goals and subgoals. Shows how to limit
    search by using models. <b>Assignment question</b>: Assume that you have a program that can prove theorems. Is this sufficient/not sufficient to indicate that you have created an intelligence program. Why or why not? 
    
    <li> <b>1961</b> <i>GPS: A Program that simulates Human Thought</i> by
    Allen Newell and Herbert Simon.  Can intelligence be revealed by any one ability? Does it require a host of abilities?  N&S provide a general problem
    solving algorithm that relies on states, goals and operators. <b>Assignment Question</b>: How is this program similar or different from the way you solve problems? 
    <li> <b>1977</b> <i>Computers and Thought Lecture</i> by Douglas Lenat. <i>The ubiquity of discovery</i>. Lenat surveys several programs that do scientific discovery, or do they? <b>Assignment question</b>: Are these programs doing scientific discovery? Argue for or against.
    
    <li> <b>1981</b> Rodney Brooks: Brooks argues that intelligence can be achieved without reason or representation, two key assumptions behind most AI research. Darpa issued a million dollar challenge for an autonomous vehicle that would traverse natural environments. Search for Humanoid robots via google. Asimov and Wakamaru are two. Others? <b>Assignment question(s)</b>: Can we build Hal?  Why or why not? What can programs do? Use specifics from readings.
 <li> <b>1982</b> Marvin Minsky <i>Why People Think Computers Can't</i>  You may find Minsky's web site interesting. <b>Assignment Questions</b>
 Do you agree that his "web of meaning" yields meaning? Do you think computers can be conscious?
 <li> <b>1999</b> Tom Mitchell <i>Machine Learning and Data Mining</i>  <b>Assignment questions: </b> Are these programs learning? Why or why not?
  <li> Tieing it all together:  <b>Assignment questions</b>: What papers did you find most valuable? Is AI achieving intelligence? 

  </ol>
  <h2> Other Potential Topics/Papers </h2>
  <ul>
        <li> What is Bioinformatics?
        <li> Can Programs do medical diagnosis?
        <li> Practical application of learning
        <li>  <i>AM: A Mathematician</i> by Douglas Lenat. Is proving theorems or solving differential equations an indication of intelligence? A more creative task is discovering theorems. Lenat
    demonstrates a heuristic approach to generate mathematical
    conjectures and definitions by examining examples.
    <li> <i>Some Studies in Machine Learning Using the Game of
    Checkers</i> by Arthur Samuel. (1954) Can programs learn? Demonstrates an effective
    learning algorithm and discusses the problem of
    representation. Does this convince you that programs can be intelligence? Why or Why not? What can programs do?
    <li> <i>The Principle Acts of Conceptual Dependency</i> by Roger Schank. (1969) Provides a
    core conceptual language that he hoped would allow for
    representing the meaning of sentences. Representation is a key problem in AI. 
    <li> <i>Mapping Ontologies into Cyc</i> by Douglas Lenat. (2002) An attempt to store everything a child knows by the age of five or common sense knowledge.
    Cyc stores world knowledge in multiple forms, including first and second order logic.
    Inference is handled by special algorithms for efficiency. Currently has several million facts and rules.
    <li><i>Prolog</i> by Kowalski.  Prolog is a programming
    language based on logic. Computation is viewed as logical
    deduction (formally resolution). In this context a program is simply a
    collection of facts and rules. You query the program and it used the facts and rules to generate a proof.
    <


        <li> 
        </ul>
 <h3> Notes </h3>
 <ul>
   <li> Complexity: $1,000,000 Clay (mathematics prize) for settling tennis pickup problem.
   Suppose you want pick up N tennis balls and return your spot, with the least amount of work. What is an upper bound on the number of operations you need to figure out the best path?
<li> Lenat on why he went into AI. (1971) <br>
One was that it was positively reinforcing --- you would be building something like a mental amplifier that would make you smarter, hence would enable you to do even more and better things. 
<br>
The second interesting property was that it was clear researchers in the field didn't know what the hell they were doing. <br>


<li> Charlie Brown on Natural Language Processing: <br>
 Lucy and Charlie are on the baseball field and it is raining. Lucy is holding an umbrella. <br>
Charlie says: "You can't catch a baseball holding an umbrella". <br>
Lucy says: "How did he know that?"
</ul>
