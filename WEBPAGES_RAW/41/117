<!DOCTYPE html 
    PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
  <title>SLI | Projects / GraphicalModels </title>
  <meta http-equiv='Content-Style-Type' content='text/css' />
  <link rel='stylesheet' href='http://sli.ics.uci.edu/pmwiki/pub/skins/custom/pmwiki.css' type='text/css' />
  <!--HTMLHeader--><style type='text/css'><!--
  ul, ol, pre, dl, p { margin-top:0px; margin-bottom:0px; }
  code.escaped { white-space: nowrap; }
  .vspace { margin-top:1.33em; }
  .indent { margin-left:40px; }
  .outdent { margin-left:40px; text-indent:-40px; }
  a.createlinktext { text-decoration:none; border-bottom:1px dotted gray; }
  a.createlink { text-decoration:none; position:relative; top:-0.5em;
    font-weight:bold; font-size:smaller; border-bottom:none; }
  img { border:0px; }
  .editconflict { color:green; 
  font-style:italic; margin-top:1.33em; margin-bottom:1.33em; }

  table.markup { border:2px dotted #ccf; width:90%; }
  td.markup1, td.markup2 { padding-left:10px; padding-right:10px; }
  table.vert td.markup1 { border-bottom:1px solid #ccf; }
  table.horiz td.markup1 { width:23em; border-right:1px solid #ccf; }
  table.markup caption { text-align:left; }
  div.faq p, div.faq pre { margin-left:2em; }
  div.faq p.question { margin:1em 0 0.75em 0; font-weight:bold; }
  div.faqtoc div.faq * { display:none; }
  div.faqtoc div.faq p.question 
    { display:block; font-weight:normal; margin:0.5em 0 0.5em 20px; line-height:normal; }
  div.faqtoc div.faq p.question * { display:inline; }
   
    .frame 
      { border:1px solid #cccccc; padding:4px; background-color:#f9f9f9; }
    .lfloat { float:left; margin-right:0.5em; }
    .rfloat { float:right; margin-left:0.5em; }
a.varlink { text-decoration:none;}

--></style>  <meta name='robots' content='index,follow' />

</head>
<body>
<!--PageHeaderFmt-->
  <div id='wikilogo'><a href='http://sli.ics.uci.edu'><img src='/pmwiki/pub/skins/custom/SLI_white.png'
    alt='SLI' border='0' /></a></div>
  <div id='wikihead'>
  <form action='http://sli.ics.uci.edu'>
    <!-- <span class='headnav'><a href='http://sli.ics.uci.edu/Projects/RecentChanges'
      accesskey='c'>Recent Changes</a> -</span> --> 
    <input type='hidden' name='n' value='Projects.GraphicalModels' />
    <input type='hidden' name='action' value='search' />
    <!-- <a href='http://sli.ics.uci.edu/Site/Search'>Search</a>: -->
    <input type='text' name='q' value='' class='inputbox searchbox' />
    <input type='submit' class='inputbutton searchbutton'
      value='Search' />
    <a href='http://sli.ics.uci.edu/Site/Search'>(?)</a>
  </form></div>
<!--/PageHeaderFmt-->
  <table id='wikimid' width='100%' cellspacing='0' cellpadding='0'><tr>
<!--PageLeftFmt-->
      <td id='wikileft' valign='top'>
        <ul><li><a class='wikilink' href='http://sli.ics.uci.edu/Classes/Classes'>Classes</a>
</li><li><a class='wikilink' href='http://sli.ics.uci.edu/Group/Group'>Group</a>
</li><li><a class='wikilink' href='http://sli.ics.uci.edu/Projects/Projects'>Research</a>
</li><li><a class='urllink' href='http://www.ics.uci.edu/~ihler/pubs.html' rel='nofollow'>Publications</a>
</li><li><a class='wikilink' href='http://sli.ics.uci.edu/Code/Code'>Code</a>
</li></ul><div class='vspace'></div><hr />
<div class='vspace'></div>
</td>
<!--/PageLeftFmt-->
      <td id='wikibody' valign='top'>
<!--PageActionFmt-->
        <div id='wikicmds'><ul><li class='browse'><a class='wikilink' href='http://sli.ics.uci.edu/Projects/GraphicalModels?action=login'>login</a>
</li></ul>
</div>
<!--PageTitleFmt-->
        <div id='wikititle'>
          <div class='pagegroup'><a href='http://sli.ics.uci.edu/Projects'>Projects</a> /</div>
          <h1 class='pagetitle'>GraphicalModels</h1></div>
<!--PageText-->
<div id='wikitext'>
<hr />
<h2>Graphical Models</h2>
<p>Graphical models are used to encode structured relationships among collections of random variables.  These relationships may be logical (for example, expressing forbidden combinations of values), but most often are probabilistic, expressing the relative likelihood of co-occurrence.  These relationships are expressed as a graph in which directly related variables are connected, which can then be used to simplify and automate reasoning over the full system.
</p>
<p class='vspace'>Our work has focused on several aspects of graphical models, including
</p><ul><li>Understanding and extending variants of the popular <em>belief propagation</em> algorithm for inference, or estimating the values of some variables given observations of others
</li><li>Adaptive or incremental inference methods, which organize calculations so that they can be efficiently reused later to rapidly find changes and update results after small modifications of the model
</li><li>Graphical models defined over continuous-valued variables, for example 2- or 3-D positions in tracking
</li><li>Learning the structure and parameters of graphical models from data
</li></ul><p><br clear='all' />
</p><hr />
<h2>Belief Propagation</h2>
<p>Loopy belief propagation (Pearl 1988) is a popular algorithm for approximate inference.  Its popularity stems in part from its extremely effective application to channel coding, first to turbo decoding and then to low-density parity check (LDPC) codes (McEliece et al. 1998).  While initially not well understood, in recent years a host of theoretical results have been obtained which help to quantify its behavior.
</p>
<p class='vspace'>Belief propagation comes in two general flavors: <em>sum-product</em>, which attempts to estimate the marginal probabilities of outcomes, and <em>max-product</em>, which attempts to estimate the most likely configuration of the variables.
</p>
<div class='vspace'></div><h3>Convergence and accuracy of sum-product</h3>
<div class='img imgcaption'><span class='rfloat'><img src='http://sli.ics.uci.edu/pmwiki/uploads/Projects/bp.gif' alt='' title='' /><br /><span class='caption'><strong>Fig 1: Bethe and SAW trees</strong></span></span></div>
<p>We have developed several results on the behavior of the sum-product algorithm, including convergence conditions and bounds on the accuracy of the resulting marginal probabilities.  Our techniques are based on analyzing the Bethe tree (or computation tree) of the BP algorithm, at right.  The Bethe tree is formed by "unrolling" the graph G around a root node (say, "1"), so that the root of the Bethe tree corresponds to node "1", the next level corresponds to "1"'s neighbors, the next to their neighbors (not including their parent, "1"), and so on.  (Figure 1, both black and red nodes.)  If G is a tree, each node will appear only once, but if not each node may have many copies within the Bethe tree.  BP at level L from the bottom of the Bethe tree corresponds to the Lth iteration of loopy BP.
</p>
<p class='vspace'>Intuitively, convergence then corresonds to mixing, or decoupling of the root distribution from the initial conditions at the leaves.  If for any set of initial conditions, the belief at the root is the same, then BP must converge to a unique fixed point.  Again intuitively, this is likely to happen if the correlations among variables is weak, and sufficiently weak that the dependence from level to level dies off fast enough to offset the increasing number of nodes at each level.
We have developed several sufficient conditions that guarantee this, using mixing properties of the factors of G (NIPS 2004, JMLR 2005).  Mooij &amp; Kappen (2007) extended our analysis to factor graphs.
</p>
<p class='vspace'>The accuracy of the the beliefs can be assessed using a subtree, called the self-avoiding walk (SAW) tree (Fig 1, black nodes).  In essence, it corresponds to the unrolling of the graph G, up to the point at which each path forms a loop.  Self-avoiding is a slight misnomer, since the walks forming this graph do intersect themselves, but only at the terminal point.  Marginal probability bounds can be computed by applying our convergence analysis to only this subtree.
</p>
<div class='vspace'></div><h3>Reweighted sum-product variants</h3>
<p>We are also very interested in so-called reweighted variants of sum-product, which enable bounds on the normalization constant (called the partition function) of the distribution.  These bounds can be used in learning, since for normalized models they correspond to the data likelihood, and can also be used to produce bounds on marginal probabilities.
</p>
<p class='vspace'>Our negative tree-reweighted BP work shows how tree-reweighted sum-product can be modified to produce a lower bound on the partition function (as opposed to an upper bound).  The resulting algorithm generalizes the structured mean field approach.
</p>
<div class='vspace'></div><h3>Reweighed max-product variants</h3>
<p>Reweighted approaches to optimization are a powerful tool for combinatorial search.  These methods are closely related to linear programming relaxations, and provide both upper and lower bounds on the optimal configuration.
Our work has developed efficient data structures to optimize and solve the resulting bounds, such as the covering tree (Yarkony et al. 2010).
<br clear='all' />
</p><hr />
<h2>Adaptive Inference</h2>
<div class='img imgcaption'><span class='rfloat'><img src='http://sli.ics.uci.edu/pmwiki/uploads/Projects/hclustering.gif' alt='' title='' /><br /><span class='caption'><strong>Fig. 2: Hierarchical clustering</strong></span></span></div>
<p>Adaptive inference describes the problem of repeatedly modifying and performing inference on a model. Since the sequence of models to be used are very similar to one another (i.e., only incremental changes are made at each stage), the results of previous inferential calculations can be used to compute the new results much faster than if performed from scratch. 
</p>
<p class='vspace'>We use a tree contraction process to define a hierarchical clustering of the nodes in the factor graph (Fig. 2).  This clustering then implies a (partial) elimination ordering on the variables in the graph.  The contraction process guarantees that for any change to the model, only O(log n) computations must be recomputed.
</p>
<p class='vspace'>Our data structure can be used to incorporate arbitrary changes, including model structure or observations, in O(log n) time.  New marginal probabilities can be computed (queried) in O(log n) time.  Moreover, without knowing their number or position a priori, we can find all changes to the optimizing configuration in O(k log n) time, where k is the number of variables whose optimal configuration has changed.
<br clear='all' />
</p><hr />
<h2>Continuous random variables</h2>
<div class='img imgcaption'><span class='rfloat'><img src='http://sli.ics.uci.edu/pmwiki/uploads/Projects/nbpprod.jpg' alt='' title='' /><br /><span class='caption'><strong>Fig 3:</strong> NBP uses Gaussian mixtures to represent beliefs</span></span></div>
<p>Graphical models for discrete valued random variables are fairly well-studied, but continuous (and non-Gaussian) random variables are much more complex, despite the fact that many real-world problems consist precisely of such systems.  We have developed several algorithms for dealing with continuous-valued distributions, including <em>nonparametric belief propagation</em> (which represents beliefs using Gaussian mixture distributions) and <em>particle belief propagation</em> (which uses importance-weighted samples).
<br clear='all' />
</p><hr />
<h2>Learning graphical models</h2>
<p>One of the most important tasks in probabilistic models is their construction based on collections of data (statistical learning).  We are interested in estimating both the structure of the model, and in its parameters given a fixed structure.  Recent emphases include using composite likelihood to improve the accuracy of the model while preserving efficiency, and exploring sequential Monte Carlo approaches to learning.
</p>
<div class='vspace'></div>
</div>

      </td>
    </tr></table>
<!--PageFooterFmt-->
  <div id='wikifoot'>
    <div class='footnav' style='float:left'> Last modified July 06, 2010, at 10:31 PM</div>
    <div class='footnav' style='float:right; text-align:right'>
    <a href="http://www.ics.uci.edu">Bren School of Information and Computer Science</a><br>
    <a href="http://www.uci.edu">University of California, Irvine</a>
    </div>
  </div>
<!--HTMLFooter--><script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(["_setAccount", "UA-24148957-2"]);
	_gaq.push(["_trackPageview"]);
	(function() {
	  var ga = document.createElement("script"); ga.type = "text/javascript"; ga.async = true;
	  ga.src = ("https:" == document.location.protocol ? "https://ssl" : "http://www") + ".google-analytics.com/ga.js";
	  var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(ga, s);
	  })();
</script>
</body>
</html>
