
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Computational Vision | ICS | UC Irvine</title>
  <link rel="stylesheet" type="text/css" href="/stylesheets/screen.css" media="all">
</head>

<body id="publications">
  <div id="outerframe">
  <div id="header">
    <h1>Computational Vision at UC Irvine &nbsp;<img src="/images/eye_small.jpg" alt="small eye"></h1>
  </div>
  <div id="tabs">
    <ul id="tabnav">
      <li id="home_tab"><a href="/index.html">home</a></li>
      <li id="projects_tab"><a href="/projects.html">projects</a></li>
      <li id="people_tab"><a href="/people.html">people</a></li>
      <li id="publications_tab"><a href="/publications.html">publications</a></li>
      <li id="datasets_tab"><a href="/datasets/index.html">datasets</a></li>
      <li id="events_tab"><a href="/events.html">events</a></li>
      <li id="courses_tab"><a href="/courses.html">courses</a></li>
      <li id="contact_tab"><a href="/contact.html">contact</a></li>
      <li id="links_tab"><a href="/links.html">links</a></li>
    </ul>
  </div>

  <div id="content">
    <div id="paper_title">Detecting Actions, Poses, and Objects with Relational Phraselets</div>
    <div id="paper_authors"><a href="/people/32.html">Chaitanya&nbsp;Desai</a>, <a href="/people/20.html">Deva&nbsp;Ramanan</a></div>
    <div id="abstract">
      <img style="float:left;" src="icon_drop.jpg" alt="icon">
      We present a novel approach to modeling human pose, together with
interacting objects, based on compositional models of local visual
interactions and their relations. Skeleton models, while flexible
enough to capture large articulations, fail to accurately model
self-occlusions and interactions. Poselets and Visual Phrases address this
limitation, but do so at the expense of requiring a large set of templates.
We combine all three approaches with a compositional model that is flexible
enough to model detailed articulations but still captures occlusions and
object interactions. Unlike much previous work on action classification,
we do not assume test images are labeled with a person, and instead
present results for “action detection” in an unlabeled image. Notably,
for each detection, our model reports back a detailed description including
an action label, articulated human pose, object poses, and occlusion
flags. We demonstrate that modeling occlusion is crucial for recognizing
human-object interactions. We present results on the PASCAL Action
Classification challenge that shows our unified model advances the
state-of-the-art for detection, action classification, and articulated pose
estimation.

    </div>
    <div id="bibtext">
      <h3>Download: <a href="/papers/DesaiR_ECCV_2012/DesaiR_ECCV_2012.pdf">pdf</a></h3>
      <h3>Text Reference</h3>
Chaitanya Desai and Deva Ramanan.
Detecting actions, poses, and objects with relational phraselets.
In <em>ECCV (4)</em>, 158&ndash;172. 2012.<br>
<h3>BibTeX Reference</h3>
@inproceedings{DesaiR_ECCV_2012,<br>
&nbsp;&nbsp;&nbsp;&nbsp;author = "Desai, Chaitanya and Ramanan, Deva",<br>
&nbsp;&nbsp;&nbsp;&nbsp;title = "Detecting Actions, Poses, and Objects with Relational Phraselets",<br>
&nbsp;&nbsp;&nbsp;&nbsp;booktitle = "ECCV (4)",<br>
&nbsp;&nbsp;&nbsp;&nbsp;year = "2012",<br>
&nbsp;&nbsp;&nbsp;&nbsp;pages = "158-172"<br>
}<br>
    </div>
  </div>
  <div id="footer">
    <div>
      <a href="/">Computational Vision</a> |
      <a href="http://www.ics.uci.edu/">School of Information and Computer Sciences</a> |
      <a href="http://www.uci.edu/">UC Irvine</a>
    </div>
    <div id="updated">&copy; 2007-2016 UC Irvine</div>
  </div>
  </div>
</body>
</html>

