<!DOCTYPE html 
    PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
  <title>SLI | Classes-CS178-Notes / BayesClassify </title>
  <meta http-equiv='Content-Style-Type' content='text/css' />
  <link rel='stylesheet' href='http://sli.ics.uci.edu/pmwiki/pub/skins/custom/pmwiki.css' type='text/css' />
  <!--HTMLHeader--><style type='text/css'><!--
  ul, ol, pre, dl, p { margin-top:0px; margin-bottom:0px; }
  code.escaped { white-space: nowrap; }
  .vspace { margin-top:1.33em; }
  .indent { margin-left:40px; }
  .outdent { margin-left:40px; text-indent:-40px; }
  a.createlinktext { text-decoration:none; border-bottom:1px dotted gray; }
  a.createlink { text-decoration:none; position:relative; top:-0.5em;
    font-weight:bold; font-size:smaller; border-bottom:none; }
  img { border:0px; }
  .editconflict { color:green; 
  font-style:italic; margin-top:1.33em; margin-bottom:1.33em; }

  table.markup { border:2px dotted #ccf; width:90%; }
  td.markup1, td.markup2 { padding-left:10px; padding-right:10px; }
  table.vert td.markup1 { border-bottom:1px solid #ccf; }
  table.horiz td.markup1 { width:23em; border-right:1px solid #ccf; }
  table.markup caption { text-align:left; }
  div.faq p, div.faq pre { margin-left:2em; }
  div.faq p.question { margin:1em 0 0.75em 0; font-weight:bold; }
  div.faqtoc div.faq * { display:none; }
  div.faqtoc div.faq p.question 
    { display:block; font-weight:normal; margin:0.5em 0 0.5em 20px; line-height:normal; }
  div.faqtoc div.faq p.question * { display:inline; }
   
    .frame 
      { border:1px solid #cccccc; padding:4px; background-color:#f9f9f9; }
    .lfloat { float:left; margin-right:0.5em; }
    .rfloat { float:right; margin-left:0.5em; }
a.varlink { text-decoration:none;}

--></style>  <meta name='robots' content='index,follow' />

</head>
<body>
<!--PageHeaderFmt-->
  <div id='wikilogo'><a href='http://sli.ics.uci.edu'><img src='/pmwiki/pub/skins/custom/SLI_white.png'
    alt='SLI' border='0' /></a></div>
  <div id='wikihead'>
  <form action='http://sli.ics.uci.edu'>
    <!-- <span class='headnav'><a href='http://sli.ics.uci.edu/Classes-CS178-Notes/RecentChanges'
      accesskey='c'>Recent Changes</a> -</span> --> 
    <input type='hidden' name='n' value='Classes-CS178-Notes.BayesClassify' />
    <input type='hidden' name='action' value='search' />
    <!-- <a href='http://sli.ics.uci.edu/Site/Search'>Search</a>: -->
    <input type='text' name='q' value='' class='inputbox searchbox' />
    <input type='submit' class='inputbutton searchbutton'
      value='Search' />
    <a href='http://sli.ics.uci.edu/Site/Search'>(?)</a>
  </form></div>
<!--/PageHeaderFmt-->
  <table id='wikimid' width='100%' cellspacing='0' cellpadding='0'><tr>
<!--PageLeftFmt-->
      <td id='wikileft' valign='top'>
        <ul><li><a class='wikilink' href='http://sli.ics.uci.edu/Classes/Classes'>Classes</a>
</li><li><a class='wikilink' href='http://sli.ics.uci.edu/Group/Group'>Group</a>
</li><li><a class='wikilink' href='http://sli.ics.uci.edu/Projects/Projects'>Research</a>
</li><li><a class='urllink' href='http://www.ics.uci.edu/~ihler/pubs.html' rel='nofollow'>Publications</a>
</li><li><a class='wikilink' href='http://sli.ics.uci.edu/Code/Code'>Code</a>
</li></ul><div class='vspace'></div><hr />
<div class='vspace'></div>
</td>
<!--/PageLeftFmt-->
      <td id='wikibody' valign='top'>
<!--PageActionFmt-->
        <div id='wikicmds'><ul><li class='browse'><a class='wikilink' href='http://sli.ics.uci.edu/Classes-CS178-Notes/BayesClassify?action=login'>login</a>
</li></ul>
</div>
<!--PageTitleFmt-->
        <div id='wikititle'>
          <div class='pagegroup'><a href='http://sli.ics.uci.edu/Classes-CS178-Notes'>Classes-CS178-Notes</a> /</div>
          <h1 class='pagetitle'>BayesClassify</h1></div>
<!--PageText-->
<div id='wikitext'>
<h2>Probability, Classifiers, and Bayes Error</h2>
<div class='vspace'></div><h2>Bayes Rule and Classifiers</h2>
<p>Bayes rule is used to compute the posterior probability of a variable, say a class c, having value C given that we have observed another variable x having value X.
<img class='TrueLatexImage' style='vertical-align:middle;' border=0 src="http://sli.ics.uci.edu/pmwiki/pub/latexcache/51831bda9f1a6ec3a777d152e8374e87.png" />
Here, <img class='TrueLatexImage' style='vertical-align:middle;' border=0 src="http://sli.ics.uci.edu/pmwiki/pub/latexcache/41621cd0d67efd1ca1f2b1d0ff4a95d0.png" /> is the probability of our observations X under class C, and <img class='TrueLatexImage' style='vertical-align:middle;' border=0 src="http://sli.ics.uci.edu/pmwiki/pub/latexcache/961b1a9a3d11b94208cbddca2790cbd9.png" /> is the prior probability of seeing class C.
</p>
<p class='vspace'>The Bayes-optimal strategy (i.e., the strategy with lowest probability of error) is then given by simply choosing to predict the value of C that has the largest posterior probability.  To see this, note that we are trying to minimize the cost 
<img class='TrueLatexImage' style='vertical-align:middle;' border=0 src="http://sli.ics.uci.edu/pmwiki/pub/latexcache/3f503a13d953879aaf4219f365ad54f8.png" />
where C is the "true" value and <img class='TrueLatexImage' style='vertical-align:middle;' border=0 src="http://sli.ics.uci.edu/pmwiki/pub/latexcache/313188757e3676b89ca37e151583b560.png" /> is our prediction based on X.
</p>
<p class='vspace'>To visualize this process, we can plot the probability density function associated with each class C separately, i.e., <img class='TrueLatexImage' style='vertical-align:middle;' border=0 src="http://sli.ics.uci.edu/pmwiki/pub/latexcache/3c94d6655c59445f26ed272c28dbabcf.png" /> as a function of x.  Since <img class='TrueLatexImage' style='vertical-align:middle;' border=0 src="http://sli.ics.uci.edu/pmwiki/pub/latexcache/9299f3491c3a8fe7a95aa6c5d02723f8.png" />, this function will have the same shape as the class-conditional distribution <img class='TrueLatexImage' style='vertical-align:middle;' border=0 src="http://sli.ics.uci.edu/pmwiki/pub/latexcache/d4721c45bc0f6b28f59a4ccc25f1518e.png" />, but will be scaled by the probability of class C.  Given any decision rule, the total probability of error will be the total mass of these densities that lie in the "wrong" region.  The figure shows three decision regions: one corresponding to low error rate within class c=0, one with low error rate in class c=1, and one (the Bayes optimal decision) with lowest total error. In each, the decision boundary is shown by a vertical black line, and for each class, the probability mass of data that will be classified incorrectly by that decision rule is shaded.
</p>
<table border='0' cellspacing='3' ><tr ><td  align='left'><a href="http://sli.ics.uci.edu/pmwiki/uploads/Classes-CS178-Notes/BayesClassify/bayes0.png" class="minilink" ><img class="mini" src="http://sli.ics.uci.edu/pmwiki/uploads/Classes-CS178-Notes/BayesClassify/th00---bayes0.png.jpg" title="bayes0" alt="bayes0" border="0" /></a></td><td  align='left'><a href="http://sli.ics.uci.edu/pmwiki/uploads/Classes-CS178-Notes/BayesClassify/bayes3.png" class="minilink" ><img class="mini" src="http://sli.ics.uci.edu/pmwiki/uploads/Classes-CS178-Notes/BayesClassify/th00---bayes3.png.jpg" title="bayes3" alt="bayes3" border="0" /></a></td><td  align='left'><a href="http://sli.ics.uci.edu/pmwiki/uploads/Classes-CS178-Notes/BayesClassify/bayes2.png" class="minilink" ><img class="mini" src="http://sli.ics.uci.edu/pmwiki/uploads/Classes-CS178-Notes/BayesClassify/th00---bayes2.png.jpg" title="bayes2" alt="bayes2" border="0" /></a></td><td  align='left'><a href="http://sli.ics.uci.edu/pmwiki/uploads/Classes-CS178-Notes/BayesClassify/bayes1.png" class="minilink" ><img class="mini" src="http://sli.ics.uci.edu/pmwiki/uploads/Classes-CS178-Notes/BayesClassify/th00---bayes1.png.jpg" title="bayes1" alt="bayes1" border="0" /></a></td></tr>
<tr ><td  align='center'><img class='TrueLatexImage' style='vertical-align:middle;' border=0 src="http://sli.ics.uci.edu/pmwiki/pub/latexcache/3c94d6655c59445f26ed272c28dbabcf.png" /> for C=0,1</td><td  align='center'>Low class 0 error</td><td  align='center'>Low class 1 error</td><td  align='center'>Lowest total error</td></tr>
</table>
<div class='vspace'></div><dl><dd><ul><li>Choose the most likely class given the data
</li></ul></dd></dl><ul><li>Bayes Error rate
<ul><li>Probability of error
</li><li>Variants: minimum risk for binary classifiers
</li></ul></li></ul><div class='vspace'></div><h2>Bayes classifiers and class-conditional distributions</h2>
<h3>MLE probability density estimation and classification</h3>
<p>Our typical MLE estimate of a discrete joint probability is, for example,
<img class='TrueLatexImage' style='vertical-align:middle;' border=0 src="http://sli.ics.uci.edu/pmwiki/pub/latexcache/9793371d69a8727afb8737f2cf75372b.png" />
For a conditional probability of some event (pattern of variables) A given another observed pattern B it is,
<img class='TrueLatexImage' style='vertical-align:middle;' border=0 src="http://sli.ics.uci.edu/pmwiki/pub/latexcache/24fd8fb55ec622088187399a8949ff46.png" />
</p>
<div class='vspace'></div><h3>Overfitting in joint distribution estimates</h3>
<ul><li>Number of parameters in the joint probability
<ul><li>What happens when we observe zero counts of something?
</li></ul></li></ul><div class='vspace'></div><h2>Naive Bayes models</h2>
<p>The Naive Bayes model assumes conditional independence among the features "x" given the class "c".  This means that, in the Bayes rule equation before, we assume that
<img class='TrueLatexImage' style='vertical-align:middle;' border=0 src="http://sli.ics.uci.edu/pmwiki/pub/latexcache/74aa1e881d20ea9269db738a3c6ad35d.png" />
and we can learn each feature distribution <img class='TrueLatexImage' style='vertical-align:middle;' border=0 src="http://sli.ics.uci.edu/pmwiki/pub/latexcache/27f1a521bdcd0ba4261460b3a390015b.png" /> individually.  Plugging into Bayes rule we have
<img class='TrueLatexImage' style='vertical-align:middle;' border=0 src="http://sli.ics.uci.edu/pmwiki/pub/latexcache/fb4b566f3c33864d0deb5d8f5f3e9fb2.png" />
</p>
<div class='vspace'></div><dl><dd><ul><li>Form and implications
</li><li>Estimating independent feature distributions
</li></ul></dd></dl>
</div>

      </td>
    </tr></table>
<!--PageFooterFmt-->
  <div id='wikifoot'>
    <div class='footnav' style='float:left'> Last modified February 26, 2012, at 08:01 PM</div>
    <div class='footnav' style='float:right; text-align:right'>
    <a href="http://www.ics.uci.edu">Bren School of Information and Computer Science</a><br>
    <a href="http://www.uci.edu">University of California, Irvine</a>
    </div>
  </div>
<!--HTMLFooter--><script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(["_setAccount", "UA-24148957-2"]);
	_gaq.push(["_trackPageview"]);
	(function() {
	  var ga = document.createElement("script"); ga.type = "text/javascript"; ga.async = true;
	  ga.src = ("https:" == document.location.protocol ? "https://ssl" : "http://www") + ".google-analytics.com/ga.js";
	  var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(ga, s);
	  })();
</script>
</body>
</html>
