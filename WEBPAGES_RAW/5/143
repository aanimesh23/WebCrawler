



<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">
<html>
<head>
<title>UCI Machine Learning Repository: Optical Recognition of Handwritten Digits Data Set: Support</title>

<!-- Stylesheet link -->
<link rel="stylesheet" type="text/css" href="../assets/ml.css" />

<script language="JavaScript" type="text/javascript">
<!--
function checkform ( form )
{
  // see http://www.thesitewizard.com/archive/validation.shtml
  // for an explanation of this script and how to use it on your
  // own website

  // ** START **
  if (form.q.value == "")
  {
    alert( "Please enter search terms." );
    form.q.focus();
    return false ;
  }

  if (getCheckedValue(form.sitesearch) == "ics.uci.edu" && form.q.value.indexOf("site:archive.ics.uci.edu/ml") == -1)
  {
    form.q.value = form.q.value + " site:archive.ics.uci.edu/ml";
  }

  // ** END **
  return true ;
}

// return the value of the radio button that is checked
// return an empty string if none are checked, or
// there are no radio buttons
function getCheckedValue(radioObj) {
	if(!radioObj)
		return "";
	var radioLength = radioObj.length;
	if(radioLength == undefined)
		if(radioObj.checked)
			return radioObj.value;
		else
			return "";
	for(var i = 0; i < radioLength; i++) {
		if(radioObj[i].checked) {
			return radioObj[i].value;
		}
	}
	return "";
}
//-->
</script>

</head>

<body>


<!-- SITE HEADER (INCLUDES LOGO AND SEARCH BOX) -->

<table width=100% bgcolor="#003366">
<tr>
	<td>
		<span class="normal"><a href="../index.html" 
alt="Home"><img src="../assets/logo.gif" 
border=0></img></a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://cml.ics.uci.edu"><font color="FFDD33">Center for Machine Learning and Intelligent Systems</font></a></span>
	</td>
	<td width=100% valign=top align="right">
		<span class="whitetext">
		<a href="../about.html">About</a>&nbsp;
		<a href="../citation_policy.html">Citation Policy</a>&nbsp;
		<a href="../donation_policy.html">Donate a Data Set</a>&nbsp;
		<a href="../contact.html">Contact</a>
		</span>

		<br>
		<br>
		<!-- Search Google -->

		<FORM method=GET action=http://www.google.com/custom onsubmit="return checkform(this);">
		<INPUT TYPE=text name=q size=30 maxlength=255 value="">
		<INPUT type=submit name=sa VALUE="Search">
		<INPUT type=hidden name=cof VALUE="AH:center;LH:130;L:http://archive.ics.uci.edu/assets/logo.gif;LW:384;AWFID:869c0b2eaa8d518e;">
		<input type=hidden name=domains value="ics.uci.edu">
		<br>
		<input type=radio name=sitesearch value="ics.uci.edu" checked> <span class="whitetext"><font size="1">Repository</font></span>
		<input type=radio name=sitesearch value=""> <span class="whitetext"><font size="1">Web</font></span>
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
		<A HREF=http://www.google.com/search><IMG SRC=http://www.google.com/logos/Logo_25blk.gif border=0 ALT=Google align=middle height=27></A>
		<br>
		</FORM>
		<!-- Search Google -->


		<span class="whitetext"><a href="../datasets.html"><font size="3" color="#FFDD33"><b>View ALL Data Sets</b></font></a></span>
		<br>
	</td>
</tr>
</table>

<br />
<table width=100% border=0 cellpadding=2><tr><td>


   <table><tr>
     <td valign=top>
	<p>
	<span class="heading"><b>Optical Recognition of Handwritten Digits Data Set</b></span>

		
				<p class="normal">Below are papers that cite this data set, with context shown.
		Papers were automatically harvested and associated with this data set, in collaboration with <a href="http://rexa.info">Rexa.info</a>.</p>
		<img src="../assets/rexa.jpg" />
		<p class="normal"><a href="/ml/datasets/Optical+Recognition+of+Handwritten+Digits">Return to Optical Recognition of Handwritten Digits data set page</a>.
		<hr><p class="normal"><a name="dedfa4527706631a09382e23555649c7b3e37ebd"></a><i>Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin. <a href="http://rexa.info/paper/dedfa4527706631a09382e23555649c7b3e37ebd">Linear dimensionalityreduction using relevance weighted LDA</a>. School of Electrical and Electronic Engineering Nanyang Technological University. 2005. </i><br><br>is generated from landsat multi-spectral scanner image data. It has 36 dimensions, 4435 training samples and 2000 testing samples belonging to 6 classes. Optdigits. This is a 60-dimensional data set on <b>optical</b> <b>recognition</b> of 10 handwritten digits. It has separate training and testing sets with 3823 and 1797 samples, respectively. Vehicle. This data set involves classification of a given<br></p><hr><p class="normal"><a name="b60b36ac9d879270bfd990b761897f1f168612b7"></a><i>Claudio Gentile. <a href="http://rexa.info/paper/b60b36ac9d879270bfd990b761897f1f168612b7">A New Approximate Maximal Margin Classification Algorithm</a>. NIPS. 2000. </i><br><br>The 214 Approximate Maximal Margin Classification real-world datasets are well-known <b>Optical</b> Character <b>Recognition</b> (OCR) benchmarks. On these datasets we followed the experimental setting described by Cortes and Vapnik (1995), Freund and Schapire (1999), Li and Long<br></p><hr><p class="normal"><a name="6c590e12408ebd3b9184e8f4634612e552a823e9"></a><i>Stephen D. Bay. <a href="http://rexa.info/paper/6c590e12408ebd3b9184e8f4634612e552a823e9">Nearest neighbor classification from multiple feature subsets</a>. Intell. Data Anal, 3. 1999. </i><br><br>or disjoint) in combination with the CNN classifier to edit and reduce the prototypes. He also reported improvements (on five domains from the UCI repository and one <b>optical</b> character <b>recognition</b> dataset) over the baseline NN classifier if the training sets were sufficiently small and thus able to generate diverse classifiers. It is important to note that both of Alpaydin's and Skalak's work differ<br></p><hr><p class="normal"><a name="4ce0d7e58fb5a580416fc6aa07ca54a2829a0091"></a><i>Ethem Alpaydin. <a href="http://rexa.info/paper/4ce0d7e58fb5a580416fc6aa07ca54a2829a0091">Combined 5 x 2 cv F Test for Comparing Supervised Classification Learning Algorithms</a>. Neural Computation, 11. 1999. </i><br><br>2 no VOWEL 2 no ODR 8 yes DIGIT 7 yes PEN 10 yes changing the numerator where we compare a single layer perceptron (LP) with a multilayer perceptron with one hidden layer (MLP). ODR, DIGIT are two datasets on <b>optical</b> handwritten digit <b>recognition</b> and PEN is on pen-based handwritten digit recognition. These three datasets are available from the author. The other datasets are from the UCI repository<br></p><hr><p class="normal"><a name="fc0a66d3a7336b6eabad919a7389c68cc37f2564"></a><i>Ayhan Demiriz and Kristin P. Bennett and John Shawe and I. Nouretdinov V.. <a href="http://rexa.info/paper/fc0a66d3a7336b6eabad919a7389c68cc37f2564">Linear Programming Boosting via Column Generation</a>. Dept. of Decision Sciences and Eng. Systems, Rensselaer Polytechnic Institute. </i><br><br>with missing values. The default handling in C4.5 has been used for missing values. USPS and Optdigits are <b>optical</b> character <b>recognition</b> datasets. USPS has 256 dimensions without missing values. Out of 7291 original training points, we use 1822 points as training data and the other 5469 as validation data. There are 2007 test points.<br></p><hr><p class="normal"><a name="01b6c0d942e55f6fbcd5def25529431bf2fa33ff"></a><i>Erick Cantï¿½-Paz and Chandrika Kamath. <a href="http://rexa.info/paper/01b6c0d942e55f6fbcd5def25529431bf2fa33ff">Using Evolutionary Algorithms to Induce Oblique Decision Trees</a>. Center for Applied Scientific Computing Lawrence Livermore National Laboratory. </i><br><br>we experimented with the <b>optical</b> digit <b>recognition</b> data set, which is also available at UCI's ML repository. This data set has 3823 instances in a training set and 1797 in a testing set; each instance is described by 64 numeric attributes. The objective is<br></p>


	</td></tr></table>



<hr>

<p class="normal"><a href="/datasets/Optical+Recognition+of+Handwritten+Digits">Return to Optical Recognition of Handwritten Digits data set page</a>.


<table cellpadding=5 align=center><tr valign=center>
		<td><p class="normal">Supported By:</p></td>
        <td><img src="../assets/nsfe.gif" height=60 /> </td>
        <td><p class="normal">&nbsp;In Collaboration With:</p></td>
        <td><img src="../assets/rexaSmall.jpg" /></td>
</tr></table>

<center>
<span class="normal">
<a href="../about.html">About</a>&nbsp;&nbsp;||&nbsp;
<a href="../citation_policy.html">Citation Policy</a>&nbsp;&nbsp;||&nbsp;
<a href="../donation_policy.html">Donation Policy</a>&nbsp;&nbsp;||&nbsp;
<a href="../contact.html">Contact</a>&nbsp;&nbsp;||&nbsp;
<a href="http://cml.ics.uci.edu">CML</a>
</span>
</center>




</body>
</html>
