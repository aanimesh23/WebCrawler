<html xmlns:v="urn:schemas-microsoft-com:vml"
xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:w="urn:schemas-microsoft-com:office:word"
xmlns:st1="urn:schemas-microsoft-com:office:smarttags"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=us-ascii">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 11">
<meta name=Originator content="Microsoft Word 11">
<link rel=File-List href="ICS273AFall06_files/filelist.xml">
<link rel=Edit-Time-Data href="ICS273AFall06_files/editdata.mso">
<!--[if !mso]>
<style>
v\:* {behavior:url(#default#VML);}
o\:* {behavior:url(#default#VML);}
w\:* {behavior:url(#default#VML);}
.shape {behavior:url(#default#VML);}
</style>
<![endif]-->
<title>Untitled Document</title>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="place"/>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="City"/>
<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Author>Welling</o:Author>
  <o:Template>Normal</o:Template>
  <o:LastAuthor>Welling</o:LastAuthor>
  <o:Revision>9</o:Revision>
  <o:TotalTime>131</o:TotalTime>
  <o:Created>2006-07-03T18:58:00Z</o:Created>
  <o:LastSaved>2006-08-30T21:40:00Z</o:LastSaved>
  <o:Pages>1</o:Pages>
  <o:Words>358</o:Words>
  <o:Characters>2044</o:Characters>
  <o:Company> UCI</o:Company>
  <o:Lines>17</o:Lines>
  <o:Paragraphs>4</o:Paragraphs>
  <o:CharactersWithSpaces>2398</o:CharactersWithSpaces>
  <o:Version>11.5606</o:Version>
 </o:DocumentProperties>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:Zoom>125</w:Zoom>
  <w:SpellingState>Clean</w:SpellingState>
  <w:GrammarState>Clean</w:GrammarState>
  <w:ValidateAgainstSchemas/>
  <w:SaveIfXMLInvalid>false</w:SaveIfXMLInvalid>
  <w:IgnoreMixedContent>false</w:IgnoreMixedContent>
  <w:AlwaysShowPlaceholderText>false</w:AlwaysShowPlaceholderText>
  <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel>
 </w:WordDocument>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:LatentStyles DefLockedState="false" LatentStyleCount="156">
 </w:LatentStyles>
</xml><![endif]--><!--[if !mso]><object
 classid="clsid:38481807-CA0E-42D2-BF39-B33AF135CC4D" id=ieooui></object>
<style>
st1\:*{behavior:url(#ieooui) }
</style>
<![endif]-->
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:Tahoma;
	panose-1:2 11 6 4 3 5 4 4 2 4;
	mso-font-charset:0;
	mso-generic-font-family:swiss;
	mso-font-pitch:variable;
	mso-font-signature:1627421319 -2147483648 8 0 66047 0;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-parent:"";
	margin:0in;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";}
h2
	{mso-margin-top-alt:auto;
	margin-right:0in;
	mso-margin-bottom-alt:auto;
	margin-left:0in;
	mso-pagination:widow-orphan;
	mso-outline-level:2;
	font-size:18.0pt;
	font-family:"Times New Roman";}
a:link, span.MsoHyperlink
	{color:blue;
	text-decoration:underline;
	text-underline:single;}
a:visited, span.MsoHyperlinkFollowed
	{color:blue;
	text-decoration:underline;
	text-underline:single;}
span.SpellE
	{mso-style-name:"";
	mso-spl-e:yes;}
span.GramE
	{mso-style-name:"";
	mso-gram-e:yes;}
@page Section1
	{size:8.5in 11.0in;
	margin:1.0in 1.25in 1.0in 1.25in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;
	mso-paper-source:0;}
div.Section1
	{page:Section1;}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-parent:"";
	mso-padding-alt:0in 5.4pt 0in 5.4pt;
	mso-para-margin:0in;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Times New Roman";
	mso-ansi-language:#0400;
	mso-fareast-language:#0400;
	mso-bidi-language:#0400;}
</style>
<![endif]--><!--[if gte mso 9]><xml>
 <o:shapedefaults v:ext="edit" spidmax="12290"/>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <o:shapelayout v:ext="edit">
  <o:idmap v:ext="edit" data="1"/>
 </o:shapelayout></xml><![endif]-->
</head>

<body bgcolor="#CCCCCC" background="../../background.gif" lang=EN-US link=blue
vlink=blue style='tab-interval:.5in'>

<div class=Section1>

<h2><span style='font-size:10.0pt;font-family:Tahoma;color:red'>Introduction to Machine Learning and Data Mining, <span class=GramE>Winter 2007</span></span></h2>
			<h2><span style='font-size:10.0pt'>ICS: 178</span></h2>
			<h2><span style="font-size:10.0pt">Instructor: Max Welling</span></h2>
			<h2><span style="font-size:10.0pt">Lecture TuTh 3.30-4.50pm PSCB220</span></h2>
			<h2><span style="font-size:10.0pt">Discussion: W 3.00-3.50pm ICS 243</span></h2>
			<h2><span style='font-size:10.0pt'>

<hr size=2 width="100%" align=left>

</span></h2>
			<h2><span style='font-size:10.0pt;font-family:Arial;color:red'>Prerequisites</span></h2>

<h2><span style="font-size:10.0pt">ICS 6A/Mathematics 6A, Mathematics 6B, Mathematics 6C or 3A, Mathematics 2A-B, Statistics 67/Mathematics 67.</span></h2>

<h2><span style='font-size:10.0pt'>

<hr size=2 width="100%" align=left>

</span></h2>

<h2><span style='font-size:10.0pt;font-family:Arial;color:red'>Goals:</span></h2>
			<h2><span style='font-size:10.0pt;color:black'>The goal of this class is to familiarize you with various state-of-the-art machine learning techniques for classification, regression, <span class=GramE>clustering</span> and dimensionality reduction. <br>
					 You will implement a number of algorithms on the netflix problem, participate in group discussions and give presentations. <br>
					 At the end of the class you will be able to apply these techniques to novel problems in academia and industry.<br>
				</span></h2>
			<h2><span style='font-size:10.0pt;font-family:Arial;color:black'>

<hr size=2 width="100%" align=left>

</span></h2>
			<h2><span class=GramE><span style='font-size:10.0pt;font-family:Arial;
color:red'>Homework :</span></span><span style='font-size:10.0pt;font-family:
Arial;color:red'>  <font color="black">Please see the slides.</font></span></h2>
			<h2><span style="font-size:10.0pt;font-family: Arial;color:red"><font color="red">Projects:  </font><font color="black"> Netflix problem. </font></span><span style="font-size:10.0pt;font-family: Arial;color:red"><font color="black"><a href="http://www.netflixprize.com/index">Netflix site</a></font></span></h2>
			<h2><span style="font-size:10.0pt;font-family: Arial;color:red"><font color="red">Code:</font><font color="black">  Here is  <a href="netflixcpp.tgz">code</a> to download the netflix data into memory (about 1Gig RAM required). Some <a href="netflix_on_solaris.txt">note</a> by Jeff Taggert</font></span></h2>
			<h2><span style='font-size:10.0pt;font-family:Arial;color:black'>

<hr size=2 width="100%" align=left>

</span></h2>
			<h2><span style='font-size:10.0pt;font-family:Arial;color:red'>Syllabus: (subject to change)</span></h2>

<h2><span class=GramE><span style="font-size:10.0pt;color:blue">1</span></span><span
style='font-size:10.0pt;color:blue'>:</span><span style='font-size:10.0pt;
color:red'> </span><span style="font-size:10.0pt">Introduction: overview, examples, goals, probability, conditional independence, matrices, eigenvalue decompositions [<a href="Intro178winter07.ppt">slides Lec 1</a>] [<a href="VisSupLearn178winter07.ppt">slides Lec 2</a>]</span></h2>

<h2><span class=GramE><span style="font-size:10.0pt;color:blue">2</span></span><span style="font-size:10.0pt;color:blue">:</span><span style='font-size:10.0pt;
color:red'> <font color="black">Optimization and Data Visualization: Stochastic gradient descent, coordinate descent, centering, sphering, histograms, scatter-plots. [<a href="SupLearn178winter07.ppt">slides Lec 3</a>] [<a href="LSRegr178winter07.ppt">slides Lec 4</a>]</font></span></h2>
			<h2><span class=GramE><span style="font-size:10.0pt;color:blue">3</span></span><span style="font-size:10.0pt;color:blue">:</span><span style='font-size:10.0pt;
color:red'>  <font color="black">Least Squares Regression, Logistic Regression, Least Squares Matrix Factorization  [<a href="SVD178winter07.ppt">slides Lec 5</a>] [<a href="LogReg178winter07.ppt">slides Lec 6</a>]</font></span></h2>
			<h2><span style="font-size:10.0pt;color:blue"><font color="#270092">4:</font><font color="black"> Clustering: k-means and soft clustering (EM), MDL penalty. <a href="Clustering178winter07.ppt">[slides Lec7]</a></font></span></h2>
			<h2><span class=GramE><span style="font-size:10.0pt;color:blue">5</span></span><span style="font-size:10.0pt;color:blue">:</span><span style='font-size:10.0pt;
color:red'>  <font color="black">Decision Trees &amp; Boosting [<a href="DTBoosting178winter07.ppt">slides Lec8</a>]</font></span></h2>
			<h2><span style="font-size:10.0pt">Classification I: emprirical Risk Minimization, k-ne</span><span style="font-size:10.0pt">arest neighbors, decision stumps, decision tree, </span></h2>
			<h2><span style="font-size:10.0pt"><span style="color:blue"> </span>Classification II: random forests, boosting.</span></h2>
			<h2><span style="font-size:10.0pt"><span style="color:blue"> </span>Neural networks: <span class=SpellE>perceptron</span>, logistic regression, multi-layer networks, back-propagation.</span></h2>
			<h2><span style="font-size:10.0pt;color:blue"> <font color="black">Regression: Least squares regression.</font></span></h2>
			<h2><span style="font-size:10.0pt;color:blue"> </span><span style="font-size:10.0pt">Dimesionality reduction: principal components analysis, Fisher linear discriminant analysis.</span></h2>
			<h2><span style="font-size:10.0pt;color:blue"> </span><span style="font-size:10.0pt">Reinforcement learning: <span class=SpellE>MDPs</span>, TD- and Q-learning, value iteration.</span></h2>
			<h2><span style="font-size:10.0pt;color:blue"> </span><span style='font-size:10.0pt'>Bayesian methods: Bayes rule, generative models, naive <span class=SpellE>Bayes</span> classifier. </span></h2>
			<hr size=2 width="100%" align=left>
			<p><strong><font color="red">Matlab Demos </font></strong></p>
			<p><span style="font-size:10.0pt;font-family: Arial;color:red"><font color="black"><a href="LSRegression.m">LSRegression</a>, <a href="testLSRegression.m">testLSR</a>, <a href="demo_LinReg.m"> LSRegression_demo</a>,  <a href="demo_LogReg.m">LogRegression_demo</a>,  <a href="plotGauss1D.m">plotGauss1D</a>,  <a href="ginput2.m">ginput2</a></font></span></p>
			<p></p>
			<hr size=2 width="100%" align=left>
			<h2></h2>
			<h2><span style='font-size:10.0pt;font-family:Arial;color:red'>Grading Criteria</span></h2>

<h2><span style='font-size:10.0pt;color:black'>Grading will be based on a combination of weekly homework,<span class=GramE><span
style='mso-spacerun:yes'>&nbsp; </span>projects,</span><span
style='mso-spacerun:yes'> </span> midterm  and a final exam.</span></h2>

<h2><span style='font-size:10.0pt;color:black'>

<hr size=2 width="100%" align=left>

</span></h2>

<h2><span style='font-size:10.0pt;font-family:Arial;color:red'>Textbook</span></h2>

<h2><span style='font-size:10.0pt;color:#000099'>
					
The textbook that will be used for this course is:</span></h2>

<h2><span style='font-size:10.0pt;color:black'>1.  R.O. <span class=SpellE>Duda</span>, P.E. Hart, D. Stork: Pattern
Classification<br>
				</span></h2>

<h2><span style='font-size:10.0pt;color:#000099'>
Optional side readings are:</span></h2>
			<h2><span style='font-size:10.0pt;color:black'>2. Tom Mitchell: Machine Learning. <i style='mso-bidi-font-style:normal'>(http://www.cs.cmu.edu/~tom/mlbook.html)<br>
					</i>3. D. MacKay: Information Theory, Inference and Learning Algorithms<br>
					4. C.M. Bishop: Neural Networks for Pattern Recognition<br>
					
5. T. <span class=SpellE>Hastie</span>, R. <span class=SpellE>Tibshirani</span>,
J.H, Friedman: The Elements of Statistical Learning <br>
					
6. B.D. Ripley: Pattern Recognition and Neural Networks</span></h2>
			<h2></h2>
			<h2></h2>
		</div>

</body>

</html>
